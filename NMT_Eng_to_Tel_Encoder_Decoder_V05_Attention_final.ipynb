{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandanareddy-enugala/NLP-SLU/blob/main/NMT_Eng_to_Tel_Encoder_Decoder_V05_Attention_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnCOOXGakV2d",
        "outputId": "9e06699e-688d-4910-fc59-5bebb6091f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCvIU-wi38dF",
        "outputId": "97606168-0631-4a98-8f1a-1bcf4ca4ccbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 102 kB/s \n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWx0ajeP38gf",
        "outputId": "69cce928-1b32-4e37-da1d-8d27edd9c693"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Collecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Any, Tuple\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "random.seed(16)\n",
        "import tensorflow as tf\n",
        "import tensorflow_text  as tf_text\n",
        "# from Bio import pairwise2\n",
        "from functools import partial\n",
        "from collections import deque\n",
        "import pathlib\n",
        "\n",
        "use_builtins = True\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0A6qwjNkonh",
        "outputId": "30a495ba-053f-4d72-f364-672eb589469b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "random.seed(16)\n",
        "import tensorflow as tf\n",
        "import tensorflow_text  as tf_text\n",
        "use_builtins = True\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io8b3SGi4Q62",
        "outputId": "01e0b74b-0040-4a37-e086-9ffc38b2f3e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataLocation = \"/content/drive/MyDrive/nlp/\"\n",
        "fileName = \"english_telugu_data.txt\"\n",
        "filePath = dataLocation + fileName\n",
        "data = []\n",
        "with open(filePath, mode='rt', encoding='utf-8') as f:\n",
        "  for line in f.readlines():\n",
        "    data.append(line)"
      ],
      "metadata": {
        "id": "sZpcmlGTkyHz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================================\n",
        "# SPLITTING DATA\n",
        "# ====================================================================================================\n",
        "# ------------------------------------------------------------------------ SPLIT INPUT & TARGET\n",
        "def split_data_into_source_target(data, splitString):  # data, \"++++$++++\"\n",
        "  print(\"Separating English & Telugu into differnt variables --->\")\n",
        "  print(\"========================================================\")\n",
        "  source_eng = []\n",
        "  target_tel = []\n",
        "  for line in data:\n",
        "      line_split = line.split(splitString)\n",
        "      source_eng.append(line_split[0])\n",
        "      target_tel.append(line_split[1])\n",
        "  print(\"English data is stored @source_eng variable which will be returned\")\n",
        "  print(\"Telugu data is stored @target_tel variable which will be returned\")\n",
        "  print(\"\\n\", \" \" * 10, \"# \" * 5, \"\\n\")\n",
        "  return source_eng, target_tel\n",
        "\n",
        "input_texts, target_texts = split_data_into_source_target(data, \"++++$++++\")\n",
        "\n",
        "input_training_data = input_texts[:100001]\n",
        "target_training_data = target_texts[:100001]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGL-yneAkyoX",
        "outputId": "8caae411-c1a3-4995-f87f-496587ad9d0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating English & Telugu into differnt variables --->\n",
            "========================================================\n",
            "English data is stored @source_eng variable which will be returned\n",
            "Telugu data is stored @target_tel variable which will be returned\n",
            "\n",
            "            # # # # #  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_training_data records  : \", len(input_training_data))\n",
        "print(\"target_training_data records : \", len(target_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hv6-pwR4hN0",
        "outputId": "4071bdc9-234c-4038-fe4c-ef8615411704"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_training_data records  :  100001\n",
            "target_training_data records :  100001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allwords=[]\n",
        "for sentence in input_training_data:\n",
        "  allwords += sentence.split(\" \")"
      ],
      "metadata": {
        "id": "b4VL6msBVS5N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(set(allwords)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-CEVr_QVznn",
        "outputId": "a8dae8eb-dafd-4dbc-a4ab-d179a501c5e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22026"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_training_data[10], target_training_data[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgeqoHQ73Ubq",
        "outputId": "6997ad1e-7796-4984-fabf-0a801580d117"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('He feels very happy.', 'అతను చాలా సంతోషంగా ఉన్నాడు.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ShapeChecker**"
      ],
      "metadata": {
        "id": "bioufCCQlEAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "        return\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, newDim in parsed.items():\n",
        "        oldDim = self.shapes.get(name, None)\n",
        "        if (broadcast and newDim == 1):\n",
        "            continue\n",
        "        if oldDim is None:\n",
        "            # It adds the axis length to the cache, if the axis name is new.\n",
        "            self.shapes[name] = newDim\n",
        "            continue\n",
        "        if newDim != oldDim:\n",
        "            raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                              f\"    found: {newDim}\\n\"\n",
        "                              f\"    expected: {oldDim}\\n\")"
      ],
      "metadata": {
        "id": "HPJ_1uK6lCrI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uniform Distribution data Creation**"
      ],
      "metadata": {
        "id": "2MQBmSNNlLZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_training_data_ud),len(target_training_data_ud),len(input_validation_data_ud),len(target_validation_data_ud)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2_y8ghtb_mR",
        "outputId": "2cdac0ff-01ee-447c-bb21-2fae8098877c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79990, 79990, 20011, 20011)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_TRAINING_DATA_SIZE = len(input_training_data)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "is_train_ud = np.random.uniform(size=(len(target_training_data),)) < 0.8\n",
        "\n",
        "input_training_data_ud=[]\n",
        "target_training_data_ud=[]\n",
        "input_validation_data_ud=[]\n",
        "target_validation_data_ud=[]\n",
        "training_indexes=[i for i,bl in enumerate(is_train_ud)  if bl==True]\n",
        "validation_indexes=[i for i,bl in enumerate(is_train_ud)  if bl!=True]\n",
        "for i in training_indexes:\n",
        "    input_training_data_ud.append(input_training_data[i])\n",
        "    target_training_data_ud.append(target_training_data[i])\n",
        "for i in validation_indexes:\n",
        "    input_validation_data_ud.append(input_training_data[i])\n",
        "    target_validation_data_ud.append(target_training_data[i])\n"
      ],
      "metadata": {
        "id": "RpQ2pREFfPwu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_training_data_ud),len(target_training_data_ud),len(input_validation_data_ud),len(target_validation_data_ud)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-rorOP7b-h3",
        "outputId": "248daee1-ffe5-429d-d2ff-dcc7ec0708c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80001, 80001, 20000, 20000)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# ================================================================================================================================================\n",
        "training_batchData = (tf.data.Dataset\n",
        "                      .from_tensor_slices((input_training_data_ud,target_training_data_ud ))\n",
        "                      .shuffle(SOURCE_TRAINING_DATA_SIZE)\n",
        "                      .batch(BATCH_SIZE)\n",
        "                      )\n",
        "\n",
        "validation_batchData = (tf.data.Dataset\n",
        "                        .from_tensor_slices((input_validation_data_ud, target_validation_data_ud))\n",
        "                        .shuffle(SOURCE_TRAINING_DATA_SIZE)\n",
        "                        .batch(BATCH_SIZE)\n",
        "                        )\n",
        "\n",
        "for input_strings, target_strings in training_batchData.take(1):\n",
        "    print(input_strings[:10])\n",
        "    print(\"=======================================\")\n",
        "    print(target_strings[:10])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-S9tWjIN0LP",
        "outputId": "031785d3-f6af-40bb-8a4f-3fb8906c6f8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Do you know whose car that is?'\n",
            " b\"It won't take me much time to do that.\" b\"That's why I'm here.\"\n",
            " b'Tell me that was a joke!' b\"Tom shouldn't have made Mary angry.\"\n",
            " b\"I'll do that no matter what you say.\" b\"I say it's worth a try.\"\n",
            " b'I want to get rich quickly.'\n",
            " b\"It's going to take time to get that done.\"\n",
            " b'There are quite a few hotels by the lake.'], shape=(10,), dtype=string)\n",
            "=======================================\n",
            "tf.Tensor(\n",
            "[b'\\xe0\\xb0\\x85\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\x8e\\xe0\\xb0\\xb5\\xe0\\xb0\\xb0\\xe0\\xb0\\xbf \\xe0\\xb0\\x95\\xe0\\xb0\\xbe\\xe0\\xb0\\xb0\\xe0\\xb1\\x81 \\xe0\\xb0\\x85\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\xae\\xe0\\xb1\\x80\\xe0\\xb0\\x95\\xe0\\xb1\\x81 \\xe0\\xb0\\xa4\\xe0\\xb1\\x86\\xe0\\xb0\\xb2\\xe0\\xb1\\x81\\xe0\\xb0\\xb8\\xe0\\xb0\\xbe?\\n'\n",
            " b'\\xe0\\xb0\\x85\\xe0\\xb0\\xb2\\xe0\\xb0\\xbe \\xe0\\xb0\\x9a\\xe0\\xb1\\x87\\xe0\\xb0\\xaf\\xe0\\xb0\\xa1\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\x95\\xe0\\xb0\\xbf \\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\x95\\xe0\\xb1\\x81 \\xe0\\xb0\\x8e\\xe0\\xb0\\x95\\xe0\\xb1\\x8d\\xe0\\xb0\\x95\\xe0\\xb1\\x81\\xe0\\xb0\\xb5 \\xe0\\xb0\\xb8\\xe0\\xb0\\xae\\xe0\\xb0\\xaf\\xe0\\xb0\\x82 \\xe0\\xb0\\xaa\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb0\\xa6\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\x85\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb1\\x81\\xe0\\xb0\\x95\\xe0\\xb1\\x87 \\xe0\\xb0\\xa8\\xe0\\xb1\\x87\\xe0\\xb0\\xa8\\xe0\\xb1\\x81 \\xe0\\xb0\\x87\\xe0\\xb0\\x95\\xe0\\xb1\\x8d\\xe0\\xb0\\x95\\xe0\\xb0\\xa1 \\xe0\\xb0\\x89\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\x85\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\x92\\xe0\\xb0\\x95 \\xe0\\xb0\\x9c\\xe0\\xb1\\x8b\\xe0\\xb0\\x95\\xe0\\xb1\\x8d \\xe0\\xb0\\x85\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\x9a\\xe0\\xb1\\x86\\xe0\\xb0\\xaa\\xe0\\xb1\\x8d\\xe0\\xb0\\xaa\\xe0\\xb1\\x81!\\n'\n",
            " b'\\xe0\\xb0\\x9f\\xe0\\xb0\\xbe\\xe0\\xb0\\xae\\xe0\\xb1\\x8d \\xe0\\xb0\\xae\\xe0\\xb1\\x87\\xe0\\xb0\\xb0\\xe0\\xb1\\x80\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\x95\\xe0\\xb1\\x8b\\xe0\\xb0\\xaa\\xe0\\xb0\\x97\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb0\\x95\\xe0\\xb1\\x82\\xe0\\xb0\\xa1\\xe0\\xb0\\xa6\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\xae\\xe0\\xb1\\x80\\xe0\\xb0\\xb0\\xe0\\xb1\\x81 \\xe0\\xb0\\x8f\\xe0\\xb0\\xae\\xe0\\xb0\\xbf \\xe0\\xb0\\x9a\\xe0\\xb1\\x86\\xe0\\xb0\\xaa\\xe0\\xb1\\x8d\\xe0\\xb0\\xaa\\xe0\\xb0\\xbf\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe \\xe0\\xb0\\xa8\\xe0\\xb1\\x87\\xe0\\xb0\\xa8\\xe0\\xb1\\x81 \\xe0\\xb0\\x9a\\xe0\\xb1\\x87\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa4\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\x87\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\xaa\\xe0\\xb1\\x8d\\xe0\\xb0\\xb0\\xe0\\xb0\\xaf\\xe0\\xb0\\xa4\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb0\\x82\\xe0\\xb0\\xa1\\xe0\\xb0\\xbf \\xe0\\xb0\\xb5\\xe0\\xb0\\xbf\\xe0\\xb0\\xb2\\xe0\\xb1\\x81\\xe0\\xb0\\xb5\\xe0\\xb1\\x88\\xe0\\xb0\\xa8\\xe0\\xb0\\xa6\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\xa8\\xe0\\xb1\\x87\\xe0\\xb0\\xa8\\xe0\\xb1\\x81 \\xe0\\xb0\\x9a\\xe0\\xb1\\x86\\xe0\\xb0\\xaa\\xe0\\xb1\\x8d\\xe0\\xb0\\xa4\\xe0\\xb1\\x81\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\xa8\\xe0\\xb1\\x87\\xe0\\xb0\\xa8\\xe0\\xb1\\x81 \\xe0\\xb0\\xa4\\xe0\\xb1\\x8d\\xe0\\xb0\\xb5\\xe0\\xb0\\xb0\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\xa7\\xe0\\xb0\\xa8\\xe0\\xb0\\xb5\\xe0\\xb0\\x82\\xe0\\xb0\\xa4\\xe0\\xb1\\x81\\xe0\\xb0\\xa1\\xe0\\xb0\\xbf\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\x95\\xe0\\xb0\\xbe\\xe0\\xb0\\xb5\\xe0\\xb0\\xbe\\xe0\\xb0\\xb2\\xe0\\xb0\\xa8\\xe0\\xb1\\x81\\xe0\\xb0\\x95\\xe0\\xb1\\x81\\xe0\\xb0\\x82\\xe0\\xb0\\x9f\\xe0\\xb1\\x81\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb1\\x81.\\n'\n",
            " b'\\xe0\\xb0\\x85\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\xaa\\xe0\\xb1\\x82\\xe0\\xb0\\xb0\\xe0\\xb1\\x8d\\xe0\\xb0\\xa4\\xe0\\xb0\\xbf \\xe0\\xb0\\x95\\xe0\\xb0\\xbe\\xe0\\xb0\\xb5\\xe0\\xb0\\xa1\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\x95\\xe0\\xb0\\xbf \\xe0\\xb0\\xb8\\xe0\\xb0\\xae\\xe0\\xb0\\xaf\\xe0\\xb0\\x82 \\xe0\\xb0\\xaa\\xe0\\xb0\\xa1\\xe0\\xb1\\x81\\xe0\\xb0\\xa4\\xe0\\xb1\\x81\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf.\\n'\n",
            " b'\\xe0\\xb0\\xb8\\xe0\\xb0\\xb0\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\xb8\\xe0\\xb1\\x81 \\xe0\\xb0\\xa6\\xe0\\xb0\\x97\\xe0\\xb1\\x8d\\xe0\\xb0\\x97\\xe0\\xb0\\xb0 \\xe0\\xb0\\x95\\xe0\\xb1\\x8a\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf \\xe0\\xb0\\xb9\\xe0\\xb1\\x8b\\xe0\\xb0\\x9f\\xe0\\xb0\\xb3\\xe0\\xb1\\x8d\\xe0\\xb0\\xb3\\xe0\\xb1\\x81 \\xe0\\xb0\\x89\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xaf\\xe0\\xb0\\xbf.\\n'], shape=(10,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbBKfX7fVP28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardization**"
      ],
      "metadata": {
        "id": "JCpcrGUn0MLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization, Lower, Strip**"
      ],
      "metadata": {
        "id": "89Bi0nWp0Ten"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Unicode normalization\n",
        "# ================================================================================================================================================\n",
        "def text_normalize_lower_strip(sentence):\n",
        "    # Split accented characters.\n",
        "    sentence = tf_text.normalize_utf8(sentence, 'NFKD')\n",
        "    #lowering all the letters\n",
        "    sentence = tf.strings.lower(sentence)\n",
        "    #removing spaces from the starting and end\n",
        "    sentence = tf.strings.strip(sentence)\n",
        "    #add([START] in the beginning and [END] in the ending)\n",
        "    sentence = tf.strings.join(['[START]', sentence, '[END]'], separator=' ')\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "zY9TTUq6kywp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validating the above function\n",
        "example_text = tf.constant('vaLidating The aBove function. ')\n",
        "print(example_text.numpy().decode())\n",
        "print(text_normalize_lower_strip(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heh9rQ9mTE7C",
        "outputId": "291d24e1-c075-456b-b021-079dec14529f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vaLidating The aBove function. \n",
            "[START] validating the above function. [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Vectorization**"
      ],
      "metadata": {
        "id": "RuaIW_rv0eTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================================================================================================\n",
        "# Text Vectorization\n",
        "# ================================================================================================================================================\n",
        "max_vocab_size = 12000\n",
        "input_text_preprocessor = tf.keras.layers.TextVectorization(standardize=text_normalize_lower_strip,\n",
        "                                                            max_tokens=max_vocab_size,\n",
        "                                                            ragged=True)\n",
        "\n",
        "input_text_preprocessor.adapt(training_batchData.map(lambda context, target: context))\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "print(input_text_preprocessor.get_vocabulary()[:10])\n",
        "\n",
        "target_text_preprocessor = tf.keras.layers.TextVectorization(standardize=text_normalize_lower_strip,\n",
        "                                                             max_tokens=max_vocab_size,\n",
        "                                                             ragged=True)\n",
        "\n",
        "target_text_preprocessor.adapt(training_batchData.map(lambda context, target: target))\n",
        "print(target_text_preprocessor.get_vocabulary()[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDK5Vktu0gYf",
        "outputId": "a5f22310-f7c6-45cd-fed3-cd4b12be5997"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', '[START]', '[END]', 'tom', 'i', 'to', 'the', 'you', 'a']\n",
            "['', '[UNK]', '[START]', '[END]', 'టామ్', 'నేను', 'మీరు', 'నాకు', 'చాలా', 'నా']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layers -> Text -> Token ID**"
      ],
      "metadata": {
        "id": "v8ZR2aSU0xy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Layers can convert a batch of strings into a batch of token IDs\n",
        "# ================================================================================================================================================\n",
        "# CHECK : NO_USE -----------------------------\n",
        "example_tokens = input_text_preprocessor(input_strings)\n",
        "print(example_tokens[:3, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odk6z7Of0gcF",
        "outputId": "7749d421-a191-494b-f46d-93605c42efd4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[2, 13, 8, 24, 827, 240, 11, 934, 3],\n",
            " [2, 26, 108, 111, 28, 123, 99, 6, 13, 47, 3], [2, 98, 55, 27, 102, 3]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layers -> Token ID -> Text**"
      ],
      "metadata": {
        "id": "YcafzlHA1F83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# The get_vocabulary method can be used to convert token IDs back to text:\n",
        "# ================================================================================================================================================\n",
        "# CHECK : NO_USE -----------------------------\n",
        "context_vocab = np.array(input_text_preprocessor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "print(' '.join(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNJNcCWI08aa",
        "outputId": "f0cfc817-acdd-471f-898d-d738a411511d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] do you know whose car that is? [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(input, target):\n",
        "    input = input_text_preprocessor(input).to_tensor()\n",
        "    target = target_text_preprocessor(target)\n",
        "    targ_in = target[:,:-1].to_tensor()\n",
        "    targ_out = target[:,1:].to_tensor()\n",
        "    return (input, targ_in), targ_out\n",
        "\n",
        "training_preprocess_data = training_batchData.map(preprocess_data, tf.data.AUTOTUNE)\n",
        "validation_preprocess_data = validation_batchData.map(preprocess_data, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "BpTHxjx91Ln5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK : Print -----------------------------\n",
        "for (input_string2, target_string2), ex_tar_out in training_preprocess_data.take(1):\n",
        "    print(input_string2[0, :10].numpy())\n",
        "    print()\n",
        "    print(target_string2[0, :10].numpy())\n",
        "    print(ex_tar_out[0, :10].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pxakcg21OLt",
        "outputId": "bf677ce3-3070-48d9-b29c-2808ac62b39e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2  994   10   76   16    7  200 9299   16 4485]\n",
            "\n",
            "[   2 4257   71   51    1 1725  937    0    0    0]\n",
            "[4257   71   51    1 1725  937    3    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder Architecture**"
      ],
      "metadata": {
        "id": "MEJ9YFLR1Y9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Encoder Architecture\n",
        "# ================================================================================================================================================\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, text_processor, units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.units = units\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                                   units,\n",
        "                                                   mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.rnn = tf.keras.layers.Bidirectional(merge_mode='sum',\n",
        "                                                 layer=tf.keras.layers.GRU(units,\n",
        "                                                                           return_sequences=True,\n",
        "                                                                           recurrent_initializer='glorot_uniform')\n",
        "                                                 )\n",
        "    def call(self, input):\n",
        "        shape_checker = ShapeChecker()\n",
        "        shape_checker(input, 'batch s')\n",
        "\n",
        "        # 2. The embedding layer looks up the embedding vector for each token.\n",
        "        input = self.embedding(input)\n",
        "        shape_checker(input, 'batch s units')\n",
        "\n",
        "        # 3. The GRU processes the sequence of embeddings.\n",
        "        input = self.rnn(input)\n",
        "        shape_checker(input, 'batch s units')\n",
        "\n",
        "        # 4. Returns the new sequence of embeddings.\n",
        "        return input\n",
        "\n",
        "    def convert_input(self, input_texts):\n",
        "        input_texts = tf.convert_to_tensor(input_texts)\n",
        "        if len(input_texts.shape) == 0:\n",
        "            input_texts = tf.convert_to_tensor(input_texts)[tf.newaxis]\n",
        "        input_tensor = self.text_processor(input_texts).to_tensor()\n",
        "        input_tensor = self(input_tensor)\n",
        "        return input_tensor\n"
      ],
      "metadata": {
        "id": "M11dYZCM1bv-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNITS = 128\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_preprocessor, UNITS)\n",
        "ex_context = encoder(input_string2)"
      ],
      "metadata": {
        "id": "86dY3J891byi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK : Print -----------------------------\n",
        "print(f'Input tokens, shape (batch, s): {input_string2.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S-LlXr01b0d",
        "outputId": "c9dddffd-b495-443c-f236-373e5a811634"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens, shape (batch, s): (32, 17)\n",
            "Encoder output, shape (batch, s, units): (32, 17, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Layer**"
      ],
      "metadata": {
        "id": "tvZWmKQW1kIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# The attention layer\n",
        "# ================================================================================================================================================\n",
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, X, context):\n",
        "        shape_checker = ShapeChecker()\n",
        "\n",
        "        shape_checker(X, 'batch t units')\n",
        "        shape_checker(context, 'batch s units')\n",
        "\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=X,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        shape_checker(X, 'batch t units')\n",
        "        shape_checker(attn_scores, 'batch heads t s')\n",
        "\n",
        "        # Cache the attention scores for plotting later.\n",
        "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "        shape_checker(attn_scores, 'batch t s')\n",
        "        self.last_attention_weights = attn_scores\n",
        "\n",
        "        X = self.add([X, attn_output])\n",
        "        X = self.layernorm(X)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "xe0o9TOD1b4D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_preprocessor.vocabulary_size(),\n",
        "                                  output_dim=UNITS,\n",
        "                                  mask_zero=True)\n",
        "ex_target_embed = embed(target_string2)\n",
        "\n",
        "result = attention_layer(ex_target_embed, ex_context)\n",
        "\n",
        "print(f'Input sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_target_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BanUGAMp1p3u",
        "outputId": "9d262198-f9de-4f39-fd6f-30c7c3f1b8c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence, shape (batch, s, units): (32, 17, 128)\n",
            "Target sequence, shape (batch, t, units): (32, 11, 128)\n",
            "Attention result, shape (batch, t, units): (32, 11, 128)\n",
            "Attention weights, shape (batch, t, s):    (32, 11, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)\n",
        "\n",
        "# Plot Graph -------------------------\n",
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(input_string2 != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "F3G7sJWD1uJa",
        "outputId": "9ef5000b-df06-457c-8f56-0b69f0e56e56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder Architecture**"
      ],
      "metadata": {
        "id": "y_WQ_zVD11zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Decoder architecture\n",
        "# ================================================================================================================================================\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.word_to_index = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(),\n",
        "                                                          mask_token='', oov_token='[UNK]'\n",
        "                                                          )\n",
        "        self.index_to_word = tf.keras.layers.StringLookup(vocabulary=text_processor.get_vocabulary(),\n",
        "                                                          mask_token='', oov_token='[UNK]',\n",
        "                                                          invert=True\n",
        "                                                          )\n",
        "        self.start_token = self.word_to_index('[START]')\n",
        "        self.end_token = self.word_to_index('[END]')\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "        # 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                                   units, mask_zero=True)\n",
        "\n",
        "        # 2. The RNN keeps track of what's been generated so far.\n",
        "        self.rnn = tf.keras.layers.GRU(units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ],
      "metadata": {
        "id": "CippDxEk131_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def call(self, context, X, state=None, return_state=False):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(X, 'batch t')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    # 1. Lookup the embeddings\n",
        "    X = self.embedding(X)\n",
        "    shape_checker(X, 'batch t units')\n",
        "\n",
        "    # 2. Process the target sequence.\n",
        "    X, state = self.rnn(X, initial_state=state)\n",
        "    shape_checker(X, 'batch t units')\n",
        "\n",
        "    # 3. Use the RNN output as the query for the attention over the context.\n",
        "    X = self.attention(X, context)\n",
        "    self.last_attention_weights = self.attention.last_attention_weights\n",
        "    shape_checker(X, 'batch t units')\n",
        "    shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "    # Step 4. Generate logit predictions for the next token.\n",
        "    logits = self.output_layer(X)\n",
        "    shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "    if return_state:\n",
        "        return logits, state\n",
        "    else:\n",
        "        return logits"
      ],
      "metadata": {
        "id": "1OAMhrWt134e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(target_text_preprocessor, UNITS)\n",
        "\n",
        "logits = decoder(ex_context, target_string2)\n",
        "print(f'encoder output shape      : (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape : (batch, t) {target_string2.shape}')\n",
        "print(f'logits shape shape        : (batch, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzFxxaXz1379",
        "outputId": "62cdf2ae-8be1-494f-d303-bbbca1b2ed58"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape      : (batch, s, units) (32, 17, 128)\n",
            "input target tokens shape : (batch, t) (32, 11)\n",
            "logits shape shape        : (batch, target_vocabulary_size) (32, 11, 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inferene Stage**"
      ],
      "metadata": {
        "id": "pQm8Y1zq2FTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cHbBNbW3kohH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Inference\n",
        "# ================================================================================================================================================\n",
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "    batch_size = tf.shape(context)[0]\n",
        "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "    embedded = self.embedding(start_tokens)\n",
        "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
        "\n",
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "    words = self.index_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, '[START]', '')\n",
        "    result = tf.strings.regex_replace(result, '[END]', '')\n",
        "    return result\n",
        "\n",
        "\n",
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature=0.0):\n",
        "    logits, state = self(context, next_token,\n",
        "                         state=state,\n",
        "                         return_state=True\n",
        "                         )\n",
        "\n",
        "    if temperature == 0.0:\n",
        "        next_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (next_token == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "    return next_token, done, state\n"
      ],
      "metadata": {
        "id": "muvnYdx32ADH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wae-P0k2AFd",
        "outputId": "6270bf5b-8cca-414d-8a2b-f67df70cb8a4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'\\xe0\\xb0\\xb5\\xe0\\xb0\\xb9\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb1\\x81. \\xe0\\xb0\\x95\\xe0\\xb0\\xa8\\xe0\\xb1\\x81\\xe0\\xb0\\x97\\xe0\\xb1\\x8a\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xa1\\xe0\\xb1\\x81. \\xe0\\xb0\\x9a\\xe0\\xb1\\x86\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf\\xe0\\xb0\\xa8 \\xe0\\xb0\\xa4\\xe0\\xb0\\xa1\\xe0\\xb0\\xbf\\xe0\\xb0\\xb8\\xe0\\xb0\\xbf\\xe0\\xb0\\xaa\\xe0\\xb1\\x8b\\xe0\\xb0\\xaf\\xe0\\xb0\\xbe\\xe0\\xb0\\xaf\\xe0\\xb0\\xbf. \\xe0\\xb0\\xa8\\xe0\\xb0\\x97\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\x82\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\xaa\\xe0\\xb0\\x9a\\xe0\\xb1\\x8d\\xe0\\xb0\\x9a\\xe0\\xb0\\xbf\\xe0\\xb0\\x95 \\xe0\\xb0\\xb5\\xe0\\xb1\\x86\\xe0\\xb0\\xa4\\xe0\\xb0\\x95\\xe0\\xb0\\x82\\xe0\\xb0\\xa1\\xe0\\xb0\\xbf. \\xe0\\xb0\\xae\\xe0\\xb1\\x81\\xe0\\xb0\\x97\\xe0\\xb0\\xbf\\xe0\\xb0\\xb8\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf? \\xe0\\xb0\\xb7\\xe0\\xb0\\xbe\\xe0\\xb0\\xaa\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x97\\xe0\\xb1\\x8d\\xe2\\x80\\x8c\\xe0\\xb0\\x95\\xe0\\xb1\\x81 \\xe0\\xb0\\x87\\xe0\\xb0\\xb0\\xe0\\xb0\\xbe\\xe0\\xb0\\x95\\xe0\\xb1\\x8d',\n",
              "       b'\\xe0\\xb0\\xae\\xe0\\xb0\\xbe\\xe0\\xb0\\xae\\xe0\\xb0\\xaf\\xe0\\xb1\\x8d\\xe0\\xb0\\xaf \\xe0\\xb0\\x95\\xe0\\xb1\\x8d\\xe0\\xb0\\xb2\\xe0\\xb0\\xbf\\xe0\\xb0\\xb7\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb0\\xae\\xe0\\xb1\\x86\\xe0\\xb1\\x96\\xe0\\xb0\\xa8\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf. \\xe0\\xb0\\xaa\\xe0\\xb1\\x86\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb0\\xbf \\xe0\\xb0\\x9a\\xe0\\xb1\\x87\\xe0\\xb0\\xaf\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb1\\x81\\xe0\\xb0\\x95\\xe0\\xb1\\x81\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xa1\\xe0\\xb1\\x81. \\xe0\\xb0\\x97\\xe0\\xb0\\xbf\\xe0\\xb0\\x9f\\xe0\\xb0\\xbe\\xe0\\xb0\\xb0\\xe0\\xb0\\xbf\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d. \\xe0\\xb0\\xa4\\xe0\\xb0\\xbe\\xe0\\xb0\\x97\\xe0\\xb1\\x81\\xe0\\xb0\\xa4\\xe0\\xb1\\x81\\xe0\\xb0\\xa8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xb0\\xe0\\xb0\\xbe? \\xe0\\xb0\\xb5\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa4\\xe0\\xb1\\x87, \\xe0\\xb0\\xae\\xe0\\xb1\\x81\\xe0\\xb0\\x97\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\xaa\\xe0\\xb1\\x81 \\xe0\\xb0\\xac\\xe0\\xb0\\xb9\\xe0\\xb1\\x81\\xe0\\xb0\\xae\\xe0\\xb0\\xa4\\xe0\\xb0\\xbf\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\xb5\\xe0\\xb0\\xb8\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb0\\xbf\\xe0\\xb0\\xa8\\xe0\\xb0\\xaa\\xe0\\xb1\\x8d\\xe0\\xb0\\xaa\\xe0\\xb1\\x81\\xe0\\xb0\\xa1\\xe0\\xb1\\x81',\n",
              "       b'\\xe0\\xb0\\xae\\xe0\\xb0\\xb0\\xe0\\xb0\\xa3\\xe0\\xb0\\xb6\\xe0\\xb0\\xbf\\xe0\\xb0\\x95\\xe0\\xb1\\x8d\\xe0\\xb0\\xb7 \\xe0\\xb0\\xb5\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xb2\\xe0\\xb0\\xbe\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\xaa\\xe0\\xb0\\xb0\\xe0\\xb1\\x8d\\xe0\\xb0\\xb5\\xe0\\xb0\\xbe\\xe0\\xb0\\xb2\\xe0\\xb1\\x87\\xe0\\xb0\\xa6\\xe0\\xb1\\x81. \\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\xb0\\xe0\\xb1\\x82\\xe0\\xb0\\xaa\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\x9a\\xe0\\xb0\\xa1\\xe0\\xb0\\xbe\\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\x95\\xe0\\xb0\\xbf \\xe0\\xb0\\x9c\\xe0\\xb0\\xb0\\xe0\\xb0\\x97\\xe0\\xb0\\xac\\xe0\\xb1\\x8b\\xe0\\xb0\\xa4\\xe0\\xb1\\x8b\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf. \\xe0\\xb0\\xb8\\xe0\\xb0\\xae\\xe0\\xb0\\xbe\\xe0\\xb0\\xb5\\xe0\\xb1\\x87\\xe0\\xb0\\xb6\\xe0\\xb0\\x82\\xe0\\xb0\\xb2\\xe0\\xb1\\x8b \\xe0\\xb0\\xaa\\xe0\\xb0\\x9a\\xe0\\xb1\\x8d\\xe0\\xb0\\x9a\\xe0\\xb0\\xac\\xe0\\xb1\\x8a\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb1\\x81 \\xe0\\xb0\\x9c\\xe0\\xb0\\xa8\\xe0\\xb0\\xbe\\xe0\\xb0\\xad\\xe0\\xb0\\xbe\\xe0\\xb0\\xb2\\xe0\\xb1\\x8b \\xe0\\xb0\\xb2\\xe0\\xb1\\x8b\\xe0\\xb0\\xaa\\xe0\\xb0\\xbe\\xe0\\xb0\\xb2\\xe0\\xb1\\x81 \\xe0\\xb0\\xb5\\xe0\\xb0\\xbf\\xe0\\xb0\\xb5\\xe0\\xb0\\xbe\\xe0\\xb0\\xb9\\xe0\\xb0\\x82'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code ReferenceTaken from :\n",
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention\n"
      ],
      "metadata": {
        "id": "_24Usg8ul24j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Prepartion: Translator**"
      ],
      "metadata": {
        "id": "NHHFk0iG2J04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Model\n",
        "# ================================================================================================================================================\n",
        "class Translator(tf.keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, units, context_text_processor, target_text_processor):\n",
        "        super().__init__()\n",
        "        # Build the encoder and decoder\n",
        "        encoder = Encoder(context_text_processor, units)\n",
        "        decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, x = inputs\n",
        "        context = self.encoder(context)\n",
        "        logits = self.decoder(context, x)\n",
        "\n",
        "        try:\n",
        "            # Delete the keras mask, so keras doesn't scale the loss+accuracy.\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "2kMZwP5v2AHs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator(UNITS, input_text_preprocessor, target_text_preprocessor)\n",
        "\n",
        "logits = model((input_string2, target_string2))\n",
        "\n",
        "print(f'Input tokens, shape  : (batch, s, units) {input_string2.shape}')\n",
        "print(f'Target tokens, shape : (batch, t) {target_string2.shape}')\n",
        "print(f'       logits, shape : (batch, t, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mz2x3o72AKR",
        "outputId": "ab7773bd-d043-4c3a-b55d-943f02610a9d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens, shape  : (batch, s, units) (32, 17)\n",
            "Target tokens, shape : (batch, t) (32, 11)\n",
            "       logits, shape : (batch, t, target_vocabulary_size) (32, 11, 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "RfwVAIJK2Une"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Training\n",
        "# ================================================================================================================================================\n",
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def masked_accuracy(Y_actual, Y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    Y_pred = tf.argmax(Y_pred, axis=-1)\n",
        "    Y_pred = tf.cast(Y_pred, Y_actual.dtype)\n",
        "\n",
        "    match_records = tf.cast(Y_actual == Y_pred, tf.float32)\n",
        "    mask_value = tf.cast(Y_actual != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match_records) / tf.reduce_sum(mask_value)"
      ],
      "metadata": {
        "id": "zlXx_h-B2ANs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',  #adam\n",
        "              loss=masked_loss,\n",
        "              metrics=[masked_accuracy, masked_loss])\n",
        "\n",
        "vocab_size = 1.0 * target_text_preprocessor.vocabulary_size()\n",
        "\n",
        "print({\"expected_loss\": tf.math.log(vocab_size).numpy(), \"expected_acc\": 1 / vocab_size})\n",
        "\n",
        "model.evaluate(validation_preprocess_data, steps=20, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vlrYPJ_2WEZ",
        "outputId": "8a75d80f-9ae5-49a4-95db-816d0e00562d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'expected_loss': 9.392662, 'expected_acc': 8.333333333333333e-05}\n",
            "20/20 [==============================] - 24s 251ms/step - loss: 9.3976 - masked_accuracy: 0.0000e+00 - masked_loss: 9.3976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 9.397582054138184,\n",
              " 'masked_accuracy': 0.0,\n",
              " 'masked_loss': 9.397582054138184}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_preprocess_data.repeat(),\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch = 100,\n",
        "                    validation_data=validation_preprocess_data,\n",
        "                    validation_steps = 20,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7wC-W2f2WGp",
        "outputId": "20bb6c05-1f92-432a-b484-6785702935bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 58s 381ms/step - loss: 6.5962 - masked_accuracy: 0.2036 - masked_loss: 6.5962 - val_loss: 5.6764 - val_masked_accuracy: 0.2514 - val_masked_loss: 5.6764\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 40s 402ms/step - loss: 5.5331 - masked_accuracy: 0.2813 - masked_loss: 5.5331 - val_loss: 5.0938 - val_masked_accuracy: 0.3250 - val_masked_loss: 5.0938\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 40s 403ms/step - loss: 5.1127 - masked_accuracy: 0.3225 - masked_loss: 5.1127 - val_loss: 4.8428 - val_masked_accuracy: 0.3498 - val_masked_loss: 4.8428\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 40s 397ms/step - loss: 4.8481 - masked_accuracy: 0.3460 - masked_loss: 4.8481 - val_loss: 4.5702 - val_masked_accuracy: 0.3782 - val_masked_loss: 4.5702\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 40s 399ms/step - loss: 4.5574 - masked_accuracy: 0.3825 - masked_loss: 4.5574 - val_loss: 4.2367 - val_masked_accuracy: 0.4150 - val_masked_loss: 4.2367\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 4.3475 - masked_accuracy: 0.4038 - masked_loss: 4.3475 - val_loss: 4.1131 - val_masked_accuracy: 0.4286 - val_masked_loss: 4.1131\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 4.1451 - masked_accuracy: 0.4270 - masked_loss: 4.1451 - val_loss: 3.8778 - val_masked_accuracy: 0.4482 - val_masked_loss: 3.8778\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 37s 374ms/step - loss: 4.0102 - masked_accuracy: 0.4410 - masked_loss: 4.0102 - val_loss: 3.7200 - val_masked_accuracy: 0.4775 - val_masked_loss: 3.7200\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 3.8497 - masked_accuracy: 0.4524 - masked_loss: 3.8497 - val_loss: 3.6531 - val_masked_accuracy: 0.4678 - val_masked_loss: 3.6531\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 38s 385ms/step - loss: 3.7196 - masked_accuracy: 0.4680 - masked_loss: 3.7196 - val_loss: 3.5446 - val_masked_accuracy: 0.4830 - val_masked_loss: 3.5446\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 38s 380ms/step - loss: 3.6603 - masked_accuracy: 0.4720 - masked_loss: 3.6603 - val_loss: 3.3256 - val_masked_accuracy: 0.4975 - val_masked_loss: 3.3256\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 3.4731 - masked_accuracy: 0.4908 - masked_loss: 3.4731 - val_loss: 3.2134 - val_masked_accuracy: 0.5133 - val_masked_loss: 3.2134\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 3.3562 - masked_accuracy: 0.5017 - masked_loss: 3.3562 - val_loss: 3.0880 - val_masked_accuracy: 0.5180 - val_masked_loss: 3.0880\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 38s 383ms/step - loss: 3.2832 - masked_accuracy: 0.5149 - masked_loss: 3.2832 - val_loss: 3.0886 - val_masked_accuracy: 0.5263 - val_masked_loss: 3.0886\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 36s 361ms/step - loss: 3.1407 - masked_accuracy: 0.5280 - masked_loss: 3.1407 - val_loss: 2.8338 - val_masked_accuracy: 0.5624 - val_masked_loss: 2.8338\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 37s 369ms/step - loss: 3.1359 - masked_accuracy: 0.5335 - masked_loss: 3.1359 - val_loss: 2.8269 - val_masked_accuracy: 0.5481 - val_masked_loss: 2.8269\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 42s 417ms/step - loss: 2.9985 - masked_accuracy: 0.5419 - masked_loss: 2.9985 - val_loss: 2.7942 - val_masked_accuracy: 0.5618 - val_masked_loss: 2.7942\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 2.9339 - masked_accuracy: 0.5479 - masked_loss: 2.9339 - val_loss: 2.7234 - val_masked_accuracy: 0.5632 - val_masked_loss: 2.7234\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.8344 - masked_accuracy: 0.5560 - masked_loss: 2.8344 - val_loss: 2.7060 - val_masked_accuracy: 0.5675 - val_masked_loss: 2.7060\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 37s 369ms/step - loss: 2.7655 - masked_accuracy: 0.5665 - masked_loss: 2.7655 - val_loss: 2.5811 - val_masked_accuracy: 0.5864 - val_masked_loss: 2.5811\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 38s 386ms/step - loss: 2.7275 - masked_accuracy: 0.5716 - masked_loss: 2.7275 - val_loss: 2.5370 - val_masked_accuracy: 0.5786 - val_masked_loss: 2.5370\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 39s 393ms/step - loss: 2.6318 - masked_accuracy: 0.5776 - masked_loss: 2.6318 - val_loss: 2.4930 - val_masked_accuracy: 0.5918 - val_masked_loss: 2.4930\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.5772 - masked_accuracy: 0.5877 - masked_loss: 2.5772 - val_loss: 2.4358 - val_masked_accuracy: 0.5911 - val_masked_loss: 2.4358\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 41s 413ms/step - loss: 2.4961 - masked_accuracy: 0.5960 - masked_loss: 2.4961 - val_loss: 2.3751 - val_masked_accuracy: 0.6046 - val_masked_loss: 2.3751\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 2.4542 - masked_accuracy: 0.5951 - masked_loss: 2.4542 - val_loss: 2.3073 - val_masked_accuracy: 0.6132 - val_masked_loss: 2.3073\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 39s 390ms/step - loss: 2.0256 - masked_accuracy: 0.6346 - masked_loss: 2.0457 - val_loss: 2.3089 - val_masked_accuracy: 0.6112 - val_masked_loss: 2.3089\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 39s 391ms/step - loss: 1.9911 - masked_accuracy: 0.6398 - masked_loss: 1.9911 - val_loss: 2.2075 - val_masked_accuracy: 0.6204 - val_masked_loss: 2.2075\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 40s 402ms/step - loss: 1.9336 - masked_accuracy: 0.6494 - masked_loss: 1.9336 - val_loss: 2.2085 - val_masked_accuracy: 0.6268 - val_masked_loss: 2.2085\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 39s 388ms/step - loss: 1.9319 - masked_accuracy: 0.6532 - masked_loss: 1.9319 - val_loss: 2.1682 - val_masked_accuracy: 0.6306 - val_masked_loss: 2.1682\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 37s 371ms/step - loss: 1.9386 - masked_accuracy: 0.6518 - masked_loss: 1.9386 - val_loss: 2.0777 - val_masked_accuracy: 0.6345 - val_masked_loss: 2.0777\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 38s 384ms/step - loss: 1.8777 - masked_accuracy: 0.6543 - masked_loss: 1.8777 - val_loss: 2.0832 - val_masked_accuracy: 0.6406 - val_masked_loss: 2.0832\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 38s 383ms/step - loss: 1.8836 - masked_accuracy: 0.6544 - masked_loss: 1.8836 - val_loss: 2.1127 - val_masked_accuracy: 0.6339 - val_masked_loss: 2.1127\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 40s 401ms/step - loss: 1.8790 - masked_accuracy: 0.6541 - masked_loss: 1.8790 - val_loss: 2.0475 - val_masked_accuracy: 0.6388 - val_masked_loss: 2.0475\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 41s 415ms/step - loss: 1.8115 - masked_accuracy: 0.6638 - masked_loss: 1.8115 - val_loss: 1.8827 - val_masked_accuracy: 0.6593 - val_masked_loss: 1.8827\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 40s 400ms/step - loss: 1.8393 - masked_accuracy: 0.6590 - masked_loss: 1.8393 - val_loss: 1.9388 - val_masked_accuracy: 0.6465 - val_masked_loss: 1.9388\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 1.7989 - masked_accuracy: 0.6635 - masked_loss: 1.7989 - val_loss: 1.9620 - val_masked_accuracy: 0.6473 - val_masked_loss: 1.9620\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 1.7654 - masked_accuracy: 0.6705 - masked_loss: 1.7654 - val_loss: 1.9011 - val_masked_accuracy: 0.6453 - val_masked_loss: 1.9011\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 1.7548 - masked_accuracy: 0.6680 - masked_loss: 1.7548 - val_loss: 1.8390 - val_masked_accuracy: 0.6662 - val_masked_loss: 1.8390\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 39s 390ms/step - loss: 1.7844 - masked_accuracy: 0.6670 - masked_loss: 1.7844 - val_loss: 1.8301 - val_masked_accuracy: 0.6611 - val_masked_loss: 1.8301\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 35s 354ms/step - loss: 1.7082 - masked_accuracy: 0.6737 - masked_loss: 1.7082 - val_loss: 1.8345 - val_masked_accuracy: 0.6613 - val_masked_loss: 1.8345\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 39s 390ms/step - loss: 1.7014 - masked_accuracy: 0.6798 - masked_loss: 1.7014 - val_loss: 1.8235 - val_masked_accuracy: 0.6637 - val_masked_loss: 1.8235\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 36s 366ms/step - loss: 1.6663 - masked_accuracy: 0.6794 - masked_loss: 1.6663 - val_loss: 1.7141 - val_masked_accuracy: 0.6752 - val_masked_loss: 1.7141\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 1.6683 - masked_accuracy: 0.6804 - masked_loss: 1.6683 - val_loss: 1.7829 - val_masked_accuracy: 0.6587 - val_masked_loss: 1.7829\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 1.6247 - masked_accuracy: 0.6901 - masked_loss: 1.6247 - val_loss: 1.7518 - val_masked_accuracy: 0.6701 - val_masked_loss: 1.7518\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 40s 399ms/step - loss: 1.6498 - masked_accuracy: 0.6819 - masked_loss: 1.6498 - val_loss: 1.6702 - val_masked_accuracy: 0.6738 - val_masked_loss: 1.6702\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 40s 398ms/step - loss: 1.6443 - masked_accuracy: 0.6848 - masked_loss: 1.6443 - val_loss: 1.6676 - val_masked_accuracy: 0.6744 - val_masked_loss: 1.6676\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 1.6191 - masked_accuracy: 0.6841 - masked_loss: 1.6191 - val_loss: 1.6577 - val_masked_accuracy: 0.6784 - val_masked_loss: 1.6577\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 37s 372ms/step - loss: 1.5526 - masked_accuracy: 0.6970 - masked_loss: 1.5526 - val_loss: 1.6528 - val_masked_accuracy: 0.6821 - val_masked_loss: 1.6528\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 39s 386ms/step - loss: 1.4937 - masked_accuracy: 0.7038 - masked_loss: 1.4937 - val_loss: 1.6979 - val_masked_accuracy: 0.6845 - val_masked_loss: 1.6979\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 1.5104 - masked_accuracy: 0.6982 - masked_loss: 1.5104 - val_loss: 1.6352 - val_masked_accuracy: 0.6715 - val_masked_loss: 1.6352\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 39s 386ms/step - loss: 1.1512 - masked_accuracy: 0.7404 - masked_loss: 1.1792 - val_loss: 1.6752 - val_masked_accuracy: 0.6790 - val_masked_loss: 1.6752\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 43s 427ms/step - loss: 1.0658 - masked_accuracy: 0.7572 - masked_loss: 1.0658 - val_loss: 1.6739 - val_masked_accuracy: 0.6860 - val_masked_loss: 1.6739\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 37s 375ms/step - loss: 1.0767 - masked_accuracy: 0.7548 - masked_loss: 1.0767 - val_loss: 1.7291 - val_masked_accuracy: 0.6730 - val_masked_loss: 1.7291\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 40s 397ms/step - loss: 1.0803 - masked_accuracy: 0.7539 - masked_loss: 1.0803 - val_loss: 1.6185 - val_masked_accuracy: 0.6986 - val_masked_loss: 1.6185\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 1.0759 - masked_accuracy: 0.7518 - masked_loss: 1.0759 - val_loss: 1.7226 - val_masked_accuracy: 0.6802 - val_masked_loss: 1.7226\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 1.0683 - masked_accuracy: 0.7558 - masked_loss: 1.0683 - val_loss: 1.5359 - val_masked_accuracy: 0.6930 - val_masked_loss: 1.5359\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 37s 368ms/step - loss: 1.0730 - masked_accuracy: 0.7528 - masked_loss: 1.0730 - val_loss: 1.4928 - val_masked_accuracy: 0.7039 - val_masked_loss: 1.4928\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 39s 394ms/step - loss: 1.1085 - masked_accuracy: 0.7506 - masked_loss: 1.1085 - val_loss: 1.5257 - val_masked_accuracy: 0.7007 - val_masked_loss: 1.5257\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 39s 394ms/step - loss: 1.0991 - masked_accuracy: 0.7499 - masked_loss: 1.0991 - val_loss: 1.6041 - val_masked_accuracy: 0.6849 - val_masked_loss: 1.6041\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 39s 391ms/step - loss: 1.0714 - masked_accuracy: 0.7540 - masked_loss: 1.0714 - val_loss: 1.6724 - val_masked_accuracy: 0.6799 - val_masked_loss: 1.6724\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 1.0981 - masked_accuracy: 0.7488 - masked_loss: 1.0981 - val_loss: 1.5709 - val_masked_accuracy: 0.6969 - val_masked_loss: 1.5709\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 37s 373ms/step - loss: 1.1076 - masked_accuracy: 0.7511 - masked_loss: 1.1076 - val_loss: 1.5537 - val_masked_accuracy: 0.6924 - val_masked_loss: 1.5537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Graph -----------------------------------\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "6pr5d8ka2WKY",
        "outputId": "2730f178-dfab-4319-bac3-dd57808bb4f8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7d11509df0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot Graph -----------------------------------\n",
        "plt.plot(history.history['masked_accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_accuracy'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "7hflgN7y2gqA",
        "outputId": "c4dff056-d478-4217-9bf2-88be7b42ad12"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7d14d1bb80>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e9JJyGkE0oSQhMINRCqDUFcdBFERVQsIIq4umtZdbGs3f25u7qILhZs6IoVFkVEXSmC0iQBpIQeEpLQQhqkZybv7487xBATEsowSeZ8nmeezNx75865Idwz933fe14xxqCUUsp9ebg6AKWUUq6liUAppdycJgKllHJzmgiUUsrNaSJQSik35+XqAE5VeHi4iY2NdXUYSinVqCQlJR0xxkTUtK7RJYLY2FgSExNdHYZSSjUqIpJW2zptGlJKKTeniUAppdycJgKllHJzja6PoCbl5eVkZGRQUlLi6lAU4OfnR1RUFN7e3q4ORSlVD00iEWRkZBAYGEhsbCwi4upw3JoxhuzsbDIyMmjfvr2rw1FK1UOTSAQlJSWaBBoIESEsLIysrCxXh6IUhaU2/v7tdgpKbMSE+dMuzJ+YUH9iQgMI8ffGy/PUWsePFJSyJTOfoGbedI4MpLlvkziFNo1EAGgSaED030I1BHlFZUx8bx2bM/NpGejL/I2ZVC+27OvlQYCvF/4+ngT4eBER6EubYD/aBDejTXAzWgb6si+niPVpuazfl8e+nKIT3t8myI9OkYF0btmcdmH+RIf4ExXSjLYhzfD3qfn0aowhI7eY9ftySUrLZUtmPh0jmjO0S0su6BxOULOam1RLbXaMAT9vz7Py+6mqySQCpZQ67vDREm5+52f2HinktQl9+V33VpSU28nILSY9p4h9OUXkF5dTWGajqNROYZmNghIbh4+V8sOOLA4fKz1hfy0DfekbE8JNg2Lo2TaYYyXl7DpcwO7DBew6fIw5a7MpKa844T2hAT608PPCz9sTP29Pmnl74uUpbD94jCzH/v19POnWugXfbT3I50kZeHoI/dqFcFHncMrshoycIivm3CIOHi3h71f34rr+0Wf996WJQCnVpOzLLuKmd9aSXVDK7En9GdIpHLC+SXdq2ZxOLZvXuY8yWwWHjpZwIL+EqJBmtA7y+82V7mXdf31eUWE4UlBKem4xGbnWyTszr5iCEhsl5XaKy+2UlldQVGbjgk7h9I0Jpm+7ELpEBuLl6YHNXsGG9Dx+2HGYZduzePF/OxGBVi38iA7xZ3DHMKJD/Ilr0+Ks/q6O00TQyNhsNry89J9NqZrsOHiMm99ZS5m9gjl3DKJPdPBp7cfHy4PoUH+iQ/3rtb2Hh9CyhR8tW/jRr13IKX+el6cH/WND6R8bykO/60p+UTl+Ph74ep39ZqCa6H0EZ9FVV11Fv3796N69O7NmzQLg22+/pW/fvvTu3Zvhw4cDUFBQwKRJk+jZsye9evVi3rx5ADRv/us3lblz5zJx4kQAJk6cyNSpUxk4cCAPP/wwP//8M4MHDyY+Pp4hQ4awY8cOAOx2Ow8++CA9evSgV69evPrqqyxdupSrrrqqcr/ff/89Y8eOPRe/DqXOqaIyGxPeXoMIfH7n4NNOAg1BkL/3OUsC0ASvCJ7+aivJ+4+e1X3GtWnBk1d2r3O7d999l9DQUIqLi+nfvz9jxozhjjvuYMWKFbRv356cnBwAnn32WYKCgti8eTMAubm5de47IyODVatW4enpydGjR/nxxx/x8vJi8eLFPProo8ybN49Zs2aRmprKxo0b8fLyIicnh5CQEP7whz+QlZVFREQE7733HrfddtuZ/UKUaoC+2LCfIwVlfHbnYDpHBro6nEalySUCV3rllVeYP38+AOnp6cyaNYuLLrqocjx9aGgoAIsXL+aTTz6pfF9ISN2XkuPGjcPT0/qGkJ+fz6233squXbsQEcrLyyv3O3Xq1Mqmo+Ofd/PNN/Phhx8yadIkVq9ezQcffHCWjliphsEYw/urUolr3YL+safeNOPumlwiqM83d2f44YcfWLx4MatXr8bf35+hQ4fSp08ftm/fXu99VO2Mqn6XdEBAQOXzv/71r1xyySXMnz+f1NRUhg4detL9Tpo0iSuvvBI/Pz/GjRunfQyqyVmdks2OQ8f4x7W9dPjyadA+grMkPz+fkJAQ/P392b59O2vWrKGkpIQVK1awd+9egMqmoREjRjBz5szK9x5vGoqMjGTbtm1UVFRUXlnU9llt27YFYPbs2ZXLR4wYwZtvvonNZjvh89q0aUObNm147rnnmDRp0tk7aKUaiPdXpRLi783o3m1cHUqjpIngLBk5ciQ2m41u3boxbdo0Bg0aREREBLNmzeLqq6+md+/ejB8/HoDHH3+c3NxcevToQe/evVm2bBkAL7zwAqNGjWLIkCG0bt261s96+OGHeeSRR4iPj6886QPcfvvtxMTE0KtXL3r37s1HH31UuW7ChAlER0fTrVs3J/0GlHKNjNwivk8+xPUDYpxys5U7EFP9VrsGLiEhwVSfmGbbtm16gqvDPffcQ3x8PJMnTz4nn6f/JupceeGb7cxasYcf/zKMtsHNXB1OgyUiScaYhJrWaWOxG+jXrx8BAQG89NJLrg5FqbOqpNzOJ+v2cVlcK00CZ0ATgRtISkpydQhKOcWXGzPJKyrn1iGxrg6lUXNqH4GIjBSRHSKyW0Sm1bB+uohsdDx2ikieM+NRSjUdxhhmr0qjS2QggzqEujqcRs1pVwQi4gnMBEYAGcA6EVlgjEk+vo0x5v4q2/8RiHdWPEqpxic9p4jPkzJYuGk/4c19uSwuksviWhET5s+61Fy2HTjK38b2dN2QUWNg8+ew7Hnw8oPI7o5HT2jVA1o0jlFMzmwaGgDsNsakAIjIJ8AYILmW7W8AnnRiPEqpRqCozMY3mw/yeVI6a1JyEIHBHcLIKSzjua+38dzX2+jayrpzOKiZN1fFn6WTbfICaBMPwfWs7nl4Oyx6EFJ/hNZ9ILA1pK+DLfN+3abfRLjiJfBs2K3wzoyuLZBe5XUGMLCmDUWkHdAeWFrL+inAFICYmJizG6VSqsFYsu0QD8/dRHZhGbFh/jx42Xlc3TeKNo6O4H3ZRfwv+SD/Sz5EYmoOfxjaqda6/6dk81yYNxlatIVJiyAktvZtywph+T9g9b/BpzmMehn63goejpb24jw4nAzJX8LaNyA/E8bNBt+6q54CkLoS5t0OvoHQ/kKIvQBiL4SA8DM9ylo1lDR1PTDXGGOvaaUxZhYwC6zho+cyMKXUyZXa7HiKnPJsX1WVlNv526JtfLA6jW6tW/DahL4MaB/6myafmDB/br+wA7df2IHCUhvNzsZ9A3npsPABaNXTej77SisZ1HRlkLoS5k+F/H3Q5yYY8fRvT9DNgqHdEOsR0RW+/jPMvgJu/AwCW508ll2L4dMJEBRlff7Gj2Hd29a6iG4w7DHoduWZH3M1zkwEmUDV32SUY1lNrgfudmIsDUrz5s0pKChwdRhKnZFjJeW8tSKFt37cS1Azb267IJYbBsQQ6FfzDFu12XbgKPd+soGdhwqYfEF7Hh7ZpV6VNwPOxjSRFXb44i4wdrjuAyjJh/fHwPujYOIiCLLu4MdeDj/8H/z4LwhtD5O+hXaD695/wiTrKuPzifD2CJjwObTsWvO2W7+wrgRadoOb51sJxl4O+zdC6grY+yN4O2eIrNNuKBMRL2AnMBwrAawDbjTGbK22XVfgW6C9qUcwTeGGsoaSCJw5t0Fj+zdR9Vdqs/PR2n28unQ3OYVlXNGzFbmF5axOySbQ14sbBsYw6fxYWgb6kZ5TxO7DBezOKiAlq4Byu8HP26qz7+ftSZmtgg/XptHCz5uXruvNxedFWB9SXgL56ZCbaj3y06Hz7yD2/PoHemgrrP/AavtvfxFc8Q/wCzpxm5Uz4PsnYMxMiL/JWpaRBB+MgeYtrSuDskKr2Wj/Boi/GUa+UP9mnuP2b4SPrgNbCQy6GzoNt/ojPBwJb8McWHAPRA2AGz+1rirOspPdUObUO4tF5ArgZcATeNcY87yIPAMkGmMWOLZ5CvAzxvxmeGlN6kwE30yDg5vP2jEA1iXj5S/UunratGlER0dz993WRc1TTz2Fl5cXy5YtIzc3l/Lycp577jnGjBkDnDwRFBQUMGbMmBrf98EHH/Diiy8iIvTq1Yv//Oc/HDp0iKlTp5KSkgLA66+/Tps2bRg1ahRbtmwB4MUXX6SgoICnnnqqshjeTz/9xA033MB5553Hc889R1lZGWFhYcyZM4fIyEgKCgr44x//SGJiIiLCk08+SX5+Pps2beLll18G4K233iI5OZnp06f/5jg0ETQexhh2HDpGdkEZXh5WE4+3p+DpIZTZKigstVNQWk5BqZ3sglI+XJtGek4xQzqGMe3yrvSKsk5amzLyeOvHvXy9aT8eIng43n9ceHNfmvl4UFJeQUm5nZJyO+V2w++7BPK3gTaCcjbB/vXWCTdvX7UoHU1EFz4AQx8Bz1quOkqPWZ216z+AzCTw9LHa2FOWW80t17wD0f2tbQ/8Am8Nhy6XW1cDVZuh9q2FD68G/zAozLL2M/oViBtz+r/o3DSrWWnfasBAsxDoMNTqZF7zGnS4BK6fAz4Bdezo9LgsEThDQ0wEGzZs4L777mP58uUAxMXF8d133xEUFESLFi04cuQIgwYNqiwbfbJEYLPZKCoq+s37kpOTGTt2LKtWrSI8PJycnBxCQ0MZP348gwcP5r777sNut1NQUEBubu5JE0FcXByvvfYaYBW8Cw4ORkR4++232bZtGy+99BJ/+ctfKC0trTzp5+bm4u3tTe/evdm+fTve3t4MGTKEN998k549e/7mODQRNGzGGHYeKmDhpv18vekAKUcKa9qKyhNwFXGtWzDt8q5c2Dm8xmGb6TlFfPTzPuwVhk4RzenYsjmdIpoT5O8NFRVwZAdkrIP0nzEZ65CsHY7PAoLbQdu+Vnt4SKzj0c7qlP12Gmz4D7RNgGvetppojjuUDOvegl8+hfJCaBkHfW+BXuPBP9Q6sf/3dqvj9pJHYOBd8NYwKD0Kd62ytqkubRV8eC1E9YOr3vi1mehMFR6BlB9gz1LYvQQKDkLXUXDtu+Dle3Y+owbuVWLiJCdsZ4mPj+fw4cPs37+frKwsQkJCaNWqFffffz8rVqzAw8ODzMxMDh06RKtWJ+8sMsbw6KOP/uZ9S5cuZdy4cYSHWx1Tx+caWLp0aeX8Ap6engQFBdU50c3x4ndgTXgzfvx4Dhw4QFlZWeXcCbXNmTBs2DAWLlxIt27dKC8vrzEJqIYrPaeI/67P5KtN+9l9uAAPgUEdwph8YXs6RTTHVmEot1cQlLmC89Y/Q0FIHPsuno6/vz+Bvt4E+HoSGuBT87j9igrI3k30/g38hY1Qkg17S2BXKZQXW4+sHVCab23vF4xE9YfuY6FtP6up5GQjY8b8GzoOg6/ugzcuhN+/BF4+8PPbkPaTNY6/xzXQbxJEJZz4DT9mIEz9CRbeD0ufgzVvQNERqy2+piQAVmfvQ7vA2//EfZ2pgHDoea31MAaOHbQ6kV1YPrvpJQIXGTduHHPnzuXgwYOMHz+eOXPmkJWVRVJSEt7e3sTGxv5mjoGanO77qvLy8qKi4tdL8pPNbfDHP/6RBx54gNGjR/PDDz/w1FNPnXTft99+O3/729/o2rWrlrR2AWMMmzLymZuUQWGpjZgwf9qF+RMTGkC7MH/CajhJHy0pZ9GmA/x3fSY/p1rj8vvHhvLsmO6M7NGaiMAq30ILs+G7v8KmTyAohoD0b4j88Rjc8BH41TB/b3kxrJ4Je5bBgY1Q5rjS9WpmtbF7+Vnfco//7DHWagePHgBhnU795NfjauskP+92mD/FWhbcDkY8Y7Xf13ZSB6t/4Jp3oNMIa/z/kD9ZieVknNRMU0kEWtReafhc0URwlowfP5477riDI0eOsHz5cj777DNatmyJt7c3y5YtIy0trV77yc/Pr/F9w4YNY+zYsTzwwAOEhYVVNg0NHz6c119//YSmocjISA4fPkx2djbNmzdn4cKFjBw5stbPOz63wfvvv1+5/PicCVWbhkJCQhg4cCDp6emsX7+eTZs2ncmvTJ2CvKIy5m/I5NN16Ww/eAw/bw9C/H2YvzGT4627l3okESyFJHn3pcwvgua+XjTz8WTbgaOU2iroEBHAQ7/rwlXxbX9boM0Yayz9t3+xRs5c9DBc9CBs+wrm3wmzfw83/dc6uR+X8oP17Tx3L7TpC71vsL7Vt4mH8POcdxNVcIw1omfzZ1YbfqdLf+10rYsI9LnBunKorZ/BDWkiOEu6d+/OsWPHaNu2La1bt2bChAlceeWV9OzZk4SEBLp2rWXIWDW1va979+489thjXHzxxXh6ehIfH8/s2bOZMWMGU6ZM4Z133sHT05PXX3+dwYMH88QTTzBgwADatm170s9+6qmnGDduHCEhIQwbNqxyEp3HH3+cu+++mx49euDp6cmTTz7J1VdfDcB1113Hxo0b6zXFpqpZ8v6jzFiyk6IyO0M6hnNBp3Di2rTA08P6hlxRYdh+8Bhr92azek82P+zMosxWQa+oIJ4f24Mre7ehhZ83JeV2MnKLKPplPj1X/gtxtLVn0plNkkAi/Ti/dyeu6NGSuEh/a70tE9IO/zoiJzfNugHq4CariWb0q1aZBLCaL5oFw6c3wzuXWU0pvi3gf4/DLx9BaAe45Uur0/Nc8vSCPjee/vu9fM5eLE1A0+ssVk43atQo7r//foYPH17rNvpvUrP0nCKmf7+T+RszudF3FYHNfHkjty8gBPt7M6RjGOV2w7rUHPKKrLmoo0ObMbxrJNclRBPXpsVvd5qRZH1jb9UDLv+7NUJm92LYt8YaH39S4rh5qR3EjYb+t9f87TojEeZcCx7e1j5L8uH8e+Gih5w2tl2dXe7VWaycJi8vjwEDBtC7d++TJgF3cfzbeH6xDTAYUzn2BQ8BTw8PvDyk8lv+vKQMPlidhgi82m0Ho1L+DcVwX89RLO38KEvTbKzek42Xp3BZXCSDOoQxsEPYyevs56bBx+OtJpvrP4bmEda3+gsfsE7We3+0OkXFA8TTOsmLh9WkEhILQdH1+3YclQC3fWeNogmMhCtn/HrVoBo9TQQusnnzZm6++eYTlvn6+rJ27VoXRVS34OBgdu7c6eownMJmr2DnoQJ+ychj4748fsnIo6DURmiADyH+PpU/i8vtpGUXkpZdxP78Yk7lgtpD4Np+UfzlvIOEffE8tL8YOg7Db+lzXHFwPVdc/SaMq6PzsqriPJgzDuxlVpt584gT1/sFQbdR9d9fXSK6wL0b698erxqNJpMIjDGuK0V7Gnr27MnGjRtdHYZTNKbmxt2HjzH9+10s3X6Y4nKrGSXY35veUcF09fcmt6ic3KIy9mQVkFNYho+XB7FhAfSPDSE2PIrYsACC/b0REQSrL1IQKozBXmGwVRjsFRXYKgzdWregoz0V3p0M4V1g/H+sk3WHodYomPdHw/l/gsH3WKNxygqhvMgaiePtb5UqCGxlnYhtZfDZzZCTYrXbR5x3bn5hmgSapCaRCPz8/MjOziYsLKxRJYOmyBhDdnY2fn5+rg7lpDLzipmxeCdzkzLw9/FiXEIU/dqF0DsqmHZh/s75O8rPhLfHWVUlJ3z+a7mDNn3gzuXw3WNWyYOVM2rfh3haycDLD3L2WDc6tb/w7Meq3EqTSARRUVFkZGSQlZXl6lAUVmKOiopydRg1OnyshFnLU/hgTRoYmHR+e+6+pBOhAacxisRWao2f9/S2mnlONlyyJN9qxik9Brd9+9u7VH0C4MqXrZursnZYr338wdvxs6wQjmZayeRoJhzdD4PusoZCKnWGmkQi8Pb2rrwjVqmq7BWGTRl5LNuRxQ87DrMpIx8PgWv6RnHfiPNOfcJze7k1fn7Lf2H7QqtEAUDzSOh1HfS+ESLjrGVlhVaZgj3LYMciq3DahM+t0T216XCx9VDqHGoSiUCpmny4Jo1/fb+TnMIyRCA+Opg/jziPK3q1pmNEPatH2sqs2lWZSVZ9nN2LoTgHfIOsuvDdrwZbMWz8CNa8Dqtehda9rbH26WutjlxPX6tk8cgX6r6TVSkX0ESgmqTcwjKe/3obXVsH8uSVcVzUOYKQupp/jLE6XzOTHCf+ROsmK3uZtb55pHUi73GNVUa4aoGwbldaxcQ2z4VNn0JJHgy809o+ZrCOtVcNmiYC1STNWZtGcbmdF67uRRfH/LY1ys+wTt57V1gn/5I8a7m3v1UqYeBUa1x+VII1audkncgB4TBoqvVQqhHRRKCanJJyO7NXpTG0S0TNSaA4z5pPdtNnVtVKgJbdrVrzx0/64V0a/ITjSp0t+peumpz5GzI5UlDKlAs7nLjiyG5Y8Q/YOt9q7gnrBJc8ZtXTCe1Q886UcgOaCFSTUlFheOvHFHq0bcHgjmHWwpy9sOKf8MvHVsdtv4m/VsrU+06U0kSgmoBDW2HlK5CTwmHCuCFXGBzfE9maZQ313DjHuhFr4FS44P4TSykrpZybCERkJDADa87it40xv5k+TESuA57Cqtf1izHmDGrLKreSkQg/vmSN0fdpDm3iqUjfxM1eWfhtXgSbsapl9psIF/4ZWrRxdcRKNUhOSwQi4gnMBEYAGcA6EVlgjEmusk1n4BHgfGNMrojoVzVVt4xEWPK0NdKnWQgMfRQG3MH6I8LVr63iid9347Z+wdYduAERVkkGpVStnHlFMADYbYxJARCRT4AxQHKVbe4AZhpjcgGMMYedGI9q7CoqYNUMWPKsNVTzsues+Wl9rZvDZi1PooWfF+MHxICv18mnLVRKVXJmImgLpFd5nQEMrLbNeQAishKr+egpY8y3ToxJNVaF2daUibu/x8SNpeTy6fg1D64sDpd6pJDvkg9y18UdCfDVri+lToWr/8d4AZ2BoUAUsEJEehpj8qpuJCJTgCkAMTEx5zpG5Wppq2HubZiiI6zt9hgPpvQj4/lVeAgE+HgR4OuFraICbw8PJg6JdXW0SjU6zkwEmUB0lddRjmVVZQBrjTHlwF4R2YmVGNZV3cgYMwuYBdZUlU6LWLlOcR4seghSf7LKMRyvvOnli0n9iXzf1kyteI41G6LoG+PHDQPbUVJup6DURmGpjcIyO4M6hNGyRcMuf61UQ+TMRLAO6Cwi7bESwPVA9RFBXwA3AO+JSDhWU1GKE2NSrpC1E/L2QcdLap7YJH0dzL0Nju2HuKsAA2VF2EoLOHT4CKvsF/N03o0M6hbL5xd3pH+stv0rdTY5LREYY2wicg/wHVb7/7vGmK0i8gyQaIxZ4Fh3mYgkA3bgIWNMtrNiUi5wcIs1sXpJnjVH7sCp0GcC+LU4sfM3qK01J25UAuX2CuasSWPGkl3kFZcztk9b/ju0I+dFnqRmkFLqtEljmlYQrKahxMREV4eh6uPIbnhvpDWW/5JHrFLN+1aDTyDE3wRHdsCepdZVwJUzMH5BLN52mP9btI2UI4UM6RjGY7/vRvc2Qa4+EqUaPRFJMsYk1LTO1Z3FqqnKTYMPRlulnW/50ppTt+8tkLke1r4B6962molGvczeduNYtOYgCzdtZtuBo3SMCOCdWxMY1rWlTj2q1DmgVwTq7Dt6AN673JrAZeLX0KrnCauNMexO3cvy7VnM3VHK9oPHAIiPCebaflFclxCNt6eHKyJXqsnSKwJ17hw7CP+5Cgqz4OYvKpPAsZJyVu4+wg87sli+M4sD+SUAJLQL4YlRcYzs0Yo2pzptpFLqrNBEoM7MsYPWvLz7Vls/D221Zu6aMBei+7M/r5gXvtnOos0HsFUYAn29OL9TOPcOj+CSri2J1OGeSrmcJgJ3l7zAqtB56VPWSJ7a7FoMyfOtO3yLsqHoiPW8NN9a7+0PUf1h6DTodiUloV15c/EuXl++G2Pg1iGxjIiLpF+7EG32UaqB0UTgzsqK4OsHrGac1B9h/ByrU7cqezkseQZWvQLNQq3pGgPCIDge/MMhOMaak7d1L/D0xhjDt1sO8tx7y8nMK+b3PVvzyBVdiQrxd80xKqXqpInAnSW+ayWBEc9Y9fzfGgZj34Buo6z1+ZnWjV7payBhMvzub+Bdc1OOvcLw3eYDvPVjChv25dG1VSAf3zHo18lhlFINliYCd1VWBCtfhg5D4fx7occ18OnN8OkEuOghiB4E86dAeQlc8441nWMNCkttfJ6YzrsrU9mXU0RMqD/Pj+3B+IRovLQJSKlGQROBuzp+NXDxNOt1UBRM+gYWPWhN6wjQMg7Gvf+b5qKKCsP6fbks3HSA+RsyyS8up1+7EB69oisj4lrh6aFj/5VqTDQRuKOyIlg5A9pfDO0G/7rc2w9GvwoxgyBrBwx9xCr+xq8n/683H+CbzQc5eLQEHy8PRnSL5LYL2tOvXYiLDkYpdaY0EbijpPeg8DAMff+360Ss8g8OJeV2vtiQyawVKaQcKcTHy4Oh50XwSK+uDO8WSXOt/a9Uo6f/i91NWRH89LLjamBIrZvlF5czZ20a761MJetYKT3atuBf1/Xmsu6t9OSvVBOj/6PdzUmuBkrK7azcfYTvkw+xcNMBCkptXNg5nJfH92FIxzCt+6NUE6WJwJ2UF1fpG7CuBo6WlPPtloMsTj7Ej7uOUFxup7mvFyPiIpl8QXt6tNXKn0o1dZoI3MXRA7D0WSg4BONmA7AuNYd7P97A/vwS2gT5MS4hiku7RTKoQxg+Xjr0Uyl3oYmgqcvaad0VvOlTqLDBgDuxRw/mtSW7mL54J1Eh/nw6ZRAD2odq049SbkoTQVNUnAdpK62JYLZ/bRWB63sLDL6Hg56tue/tNaxJyWF07zY8P7YHgX7ero5YKeVCmgiaAnu5Nen73uWwdwXs3wCmAvyCrbuEB94JAeEs2XaIBz9fQUl5Bf+8thfX9ovSqwCllCaCRq/wCHx8PWSsAw8vqwLoRQ9ZHcJRCeDlS6nNzv8t2MrsVal0a92CV2+Ip1PL5q6OXCnVQDg1EYjISGAG1uT1bxtjXqi2fiLwTyDTsejfxpi3nRlTk5K9Bz68Bo4dgDGvQdwY8D3xBL8nq4A/fiiWANYAABpKSURBVLSB5ANHmTgklmmXd8XP29NFASulGiKnJQIR8QRmAiOADGCdiCwwxiRX2/RTY8w9zoqjyUr/2boSMAZu/QqiB5yw2hjD3KQMnlywFV8vD96+JYFL4yJdFKxSqiFz5hXBAGC3MSYFQEQ+AcYA1ROBOlXbvoJ5t0Nga7hpHoR1PGH1/rxinv5qK99tPcTA9qHMuD6eVkE6E5hSqmbOTARtgfQqrzOAgTVsd42IXATsBO43xqRX30BEpgBTAGJiYpwQaiNhDKyeCf97HNr2gxs/hYDwytXl9gre/WkvM5bsosIYHh7ZhTsv6qjVQJVSJ+XqzuKvgI+NMaUicifwPjCs+kbGmFnALICEhARzbkNsIMqL4at7rfsBul0JY2dVVgYFWJuSzV+/3MLOQwVc2q0lT17ZnehQnRVMKVU3ZyaCTCC6yusofu0UBsAYk13l5dvAP5wYT+OVnwGfTIADG+GSx+HCP4OHdeevMYYX/7eDmcv20Da4GW/dksAI7QtQSp0CZyaCdUBnEWmPlQCuB26suoGItDbGHHC8HA1sc2I8jVPaKvjsFmumsBs+gS6Xn7B6xpJdzFy2h/EJ0Tw1ujvNfHREkFLq1DgtERhjbCJyD/Ad1vDRd40xW0XkGSDRGLMA+JOIjAZsQA4w0VnxNEpJs+HrP0NwO5j4NUR0OWH1m8v38PLiXVzbL4r/u7onHtoXoJQ6DWJM42pyT0hIMImJia4O48zYSq2x/yGxNa+vsMP//gprZkKnEXDN29As+IRNPlidyhNfbmVUr9bMuD5eO4SVUiclIknGmISa1mmJSVf44i6Y0Rvm3gY5KSeuKz0GH99gJYGBd1nNQdWSwGfr0nniy62MiItk+vg+mgSUUmfE1aOG3M/uJbBlHsReCDu+geQvIeE2uOhhsBXDR9dD1nb4/b+g/2TA6hDOyC1m/b5cft6bw0c/7+Oi8yL4943xeHtqLldKnRlNBOdSebHV5h/a0boRrDgXlv8d1r1jVQr18gW7zVrX8RLWpmTz7sq9JKXlcaSgFAB/H09G9WrDP67pha+Xdgwrpc6cJoJz6afpkLsXbv7COukHtoJR02HQH6xJY7JT4Np3IeI85iZlMG3eJsKa+3BR53Di24XQNyaYLpGBeOlVgFLqLNJEcK4c2W0lgh7XQsdLTlwX3hmu+wCwmoGmf7+TV5bs4vxOYbx+Uz9a6HwBSiknqnciEJEhQGzV9xhjPnBCTE2PMfD1A+DVDH73t1o3K7XZeWTeZv67IZNx/aJ4fmxPnTJSKeV09UoEIvIfoCOwEbA7FhtAE0F9bJlnTRpzxYsQWPNdv3lFZUz9MIk1KTk8eNl53H1JJ500Ril1TtT3iiABiDON7aaDhqA4D759BNrEW6ODqjHGsHDTAZ7+KpmjxeXMuL4PY/q0dUGgSil3Vd9EsAVoBRyoa0NVRYUdFtwDRUdgwmfgceIon/ScIv765RZ+2JFFz7ZBzJ7Unx5tg1wUrFLKXdU3EYQDySLyM1B6fKExZrRTomoKjLGGim77Ci573roicLDZK3h35V6mf78LEXhiVBy3DonVG8OUUi5R30TwlDODaJKWPQ9J78EF98OQXydgO3y0hHs+2sDPqTlc2q0lT4/pQdvgZi4MVCnl7uqVCIwxy0WkHdDZGLNYRPyxCsmpmqx5A1b8E/reAsOfrFy8NiWbez7eQEGJjenje3NVn7baIayUcrn6jhq6A2uGsFCs0UNtgTeA4c4LrZHa9Bl8+xfoOgp+Px1EMMbw9o97eeHb7bQL9efDyQPp0irQ1ZEqpRRQ/6ahu7HmIF4LYIzZJSItnRZVY7V1vlVQLvZCuOYd8PSioNTGw3N/YdHmg4zs3op/jutFoN4gppRqQOqbCEqNMWXHmzFExAvrPgIFYCuD75+Ata9DVH+4/iPw9sNeYfjDnPX8tCuLRy7vypSLOmhTkFKqwalvIlguIo8CzURkBPAHrPmGVd4++HwiZCZZZaNHPANePgC8smQXK3Zm8fzYHkwY2M61cSqlVC3qmwimAZOBzcCdwCJjzFtOi6qx2PENzJ8KpsKqFRQ3pnLVsh2HeWXpLq7pG8WNA2JcGKRSSp1cvYePGmOeAN4CEBFPEZljjJngvNAauI0fwxdToVUvuO59CO1QuSo9p4j7PtlI11YteO6qHtocpJRq0Opb0SxaRB4BEBEfYB6wy2lRNXS2UqtsdFR/mPz9CUmgpNzOH+asp8IYXp/QVyeTV0o1ePVNBLcBPR3JYCGw3BjzVF1vEpGRIrJDRHaLyLSTbHeNiBgRqXE+zQZn4xw4mglDHwFvvxNWPf1VMpsz8/nXdX2IDQ9wUYBKKVV/J00EItJXRPoC8cAMYDzWlcByx/KTvdcTmAlcDsQBN4hIXA3bBQL34hia2uDZy615BdomQMdhJ6z6bF06H/+8jz8M7ciIuJqrjCqlVENTVx/BS9Ve52Kd1F/CGj467Dfv+NUAYLcxJgVARD4BxgDJ1bZ7Fvg78FA9Y3atTZ9aI4WueBGqtP2v3pPNo/M3c2HncB4YcZ4LA1RKqVNz0kRgjLnkZOvr0BZIr/I6AxhYdQPHVUW0MeZrEak1EYjIFKw7m4mJceEIHLsNVrwIrXtD58sqF+89Ushdc5KIDQ/g3zf21akklVKNSr3OWCISJCL/EpFEx+MlETmjeski4gH8C/hzXdsaY2YZYxKMMQkRERFn8rFnZss8a87hix6uvBrIKyrjttnr8BDh3Vv7E9RM7xpWSjUu9f3q+i5wDLjO8TgKvFfHezKB6CqvoxzLjgsEegA/iEgqMAhY0GA7jCvsViG5lt2hyxUAlNkqmPphEpm5xcy6uR8xYf4uDlIppU5dfe8j6GiMuabK66dFZGMd71kHdBaR9lgJ4HrgxuMrjTH5WPMcACAiPwAPGmMS6xnTuZX8BWTvgnGzwcMDYwyPf7GZNSk5vDy+Dwmxoa6OUCmlTkt9rwiKReSC4y9E5Hyg+GRvMMbYgHuA74BtwGfGmK0i8oyINK4JbSoqrL6B8C7Qzbp7+OOf0/ksMYM/DevEVfE6taRSqvGq7xXBVOCDKv0CucCtdb3JGLMIWFRt2RO1bDu0nrGce9sWwOFkuPot8PCgpNzOjCU76R8bwn2X6gghpVTjVt9EcNQY01tEWgAYY446mnyavtJj8N1jENENul8NwOeJ6Rw6Wsr06/rgodNLKqUaufo2Dc0DKwEYY446ls11TkgNzNLnrbuIR78Cnl6U2uy89sMeEtqFMLhjmKujU0qpM3bSKwIR6Qp0B4JE5Ooqq1oAfjW/qwnJSIK1b0D/yRA9AIC5SRkcyC/h79f00mJySqkmoa6moS7AKCAYuLLK8mPAHc4KqkGwl8NX90JgKxhudWuU2Sp4bdke+kQHc2Hn8Dp2oJRSjUNdicAfeBCYZYxZfQ7iaThWz4RDm2H8h+Bn9ZHP35BBZl4xz43V0tJKqaajrkQQA3wOeIvIEuAb4GdjTNOepjInBX54wZqAvpt1IVRur+Dfy3bTKyqIoee58O5mpZQ6y07aWWyM+bsxZhhwBfALVjnq9SLykYjcIiJNr8SmMbDwAfDwgsv/Ubn4iw2ZpOcU86dhnfVqQCnVpNRr+Kgx5hgw3/HAUU76cuAD4HdOi84VfvkYUpZZ1UWDrBvFbPYKZi7bTfc2LRjeraWLA1RKqbOrrvkIbqry/Pzjz40xyUCpMaZpJYHsPbDoIYgZAgm3VS6em5RBanYRfxquVwNKqaanrvsIHqjy/NVq626jKbGVwbzJVpPQ1bPAw5pictehYzyzMJkBsaGM6Nb0WsKUUqqupiGp5XlNrxu3pc/C/g1w3X8g2CqaWlhq46456/H38eTVG+P1LmKlVJNUVyIwtTyv6XXjtXsJrHrFag6Ks+rhGWN45L+bSckq4MPbBxLZounfP6eUck91JYKuIrIJ69t/R8dzHK87ODWyc6XgMMyfatUS+t3fKhd/uHYfC37Zz0O/68KQjnrzmFKq6aorEfQGIjlxykmwJpw56JSIzqWKCvjiLig9Crd8Cd7NAPglPY9nv0rmki4R3HVxRxcHqZRSzlVXZ/F0IN8Yk1b1AeQ71jVumz6B3Yvhd89DZBxgTT35hznriQj0Zfp4rS6qlGr66koEkcaYzdUXOpbFOiWic2nntxAUDQmTKxe9vHgXh46W8NqEvgT7+7gwOKWUOjfqSgTBJ1nX7GwGcs4ZA2mroN35lRPRHy0p5/PEdEb3bkPv6JMdulJKNR11JYJEEflNlVERuR1Ick5I58iRnVCYBbGV98nx2bp0CsvsTDrfPebcUUopqLuz+D5gvohM4NcTfwLgA4x1ZmBOl7bS+tnOSgT2CsPsVakMiA2lZ1TQSd6olFJNS11F5w4ZY4YATwOpjsfTxpjBxpg6Rw2JyEgR2SEiu0VkWg3rp4rIZhHZKCI/OWoYnRupK6F5Kwi1RsF+n3yIjNxibrsg9pyFoJRSDUF9i84tA5adyo5FxBOYCYwAMoB1IrLAUafouI+MMW84th8N/AsYeSqfc1qMsa4IYn/tH3h35V6iQpoxIq6V0z9eKaUakvrOWXw6BgC7jTEpxpgy4BNgTNUNqsx/DBDAubpbOXcvHDsA7YYAsCUzn5/35jBxSCyeOlxUKeVm6nVFcJracuKNaBnAwOobicjdWMXtfIBhNe1IRKYAUwBiYmLOPLLU4/0DFwDW1UCAjyfX9Y8+830rpVQj48wrgnoxxsw0xnQE/gI8Xss2s4wxCcaYhIiIszA7WNpK8A+DiC4cPlbCV7/sZ1xCNC38vM9830op1cg4MxFkYpWiOC7Ksaw2nwBXOTGeX6WttJqFRPhwzT5sFYZbh8Sek49WSqmGxpmJYB3QWUTai4gPcD2woOoGItK5ysvfA7ucGI8lLx3y9kG7CygptzNnTRrDu7akfXiA0z9aKaUaIqf1ERhjbCJyD/Ad4Am8a4zZKiLPAInGmAXAPSJyKVAO5AK3OiueSsfvH4g9n683HSC7sIzb9AYypZQbc2ZnMcaYRcCiasueqPL8Xmd+fo3SVoJfELSM48cfNhER6MvgjmHnPAyllGooXN5ZfM6lrrTmJPbwJDEtl4R2IToPsVLKrblXIjh2EHL2QOz5HMwvISO3mH7tQlwdlVJKuZR7JYIq9YUS03IA6B8b6sKAlFLK9dwrEaSuBJ9AaNWLxNRcmnl7EtemhaujUkopl3KvRJC2EmIGgqcXSWm59I4OwtvTvX4FSilVnfucBQuPQNZ2aHc+haU2kg8c1WYhpZTCnRJB2irrZ7vz2Zieh73CaEexUkrhTong2EGrvlCbeBJTcxGBvpoIlFLKuTeUNSgDp0D/yY77B3LoEhmoReaUUgp3uiIA8PDEXmHYsC+PhFi9GlBKKXC3RABsP3iUglIbCe20o1gppcANE0FSWi6AXhEopZSD2yWCdam5tGrhR9vgZq4ORSmlGgS3SwRJqTn0i9VCc0opdZxbJYLMvGL255fQX4eNKqVUJbdKBImpVqG5BL2jWCmlKrlVIkhKy8Xfx5OurQJdHYpSSjUYbpUIElNz6RsTgpcWmlNKqUpOPSOKyEgR2SEiu0VkWg3rHxCRZBHZJCJLRKSds2I5VlLO9oNHtb6QUkpV47REICKewEzgciAOuEFE4qpttgFIMMb0AuYC/3BWPBv25VFh9P4BpZSqzplXBAOA3caYFGNMGfAJMKbqBsaYZcaYIsfLNUCUs4JZvy8XD4H4GE0ESilVlTOLzrUF0qu8zgAGnmT7ycA3Na0QkSnAFICYmJjTCubuSzpxRc/WNPd1nzp7SilVHw2i11REbgISgH/WtN4YM8sYk2CMSYiIiDitz/D29OC8SB0tpJRS1Tnz63EmEF3ldZRj2QlE5FLgMeBiY0ypE+NRSilVA2deEawDOotIexHxAa4HFlTdQETigTeB0caYw06MRSmlVC2clgiMMTbgHuA7YBvwmTFmq4g8IyKjHZv9E2gOfC4iG0VkQS27U0op5SRO7Tk1xiwCFlVb9kSV55c68/OVUkrVrUF0FiullHIdTQRKKeXmNBEopZSb00SglFJuThOBUkq5OU0ESinl5jQRKKWUm9NEoJRSbk4TgVJKuTlNBEop5eY0ESillJvTRKCUUm5OE4FSSrk5TQRKKeXmNBEopZSb00SglFJuThOBUkq5OU0ESinl5jQRKKWUm3NqIhCRkSKyQ0R2i8i0GtZfJCLrRcQmItc6MxallFI1c1oiEBFPYCZwORAH3CAicdU22wdMBD5yVhxKKaVOzsuJ+x4A7DbGpACIyCfAGCD5+AbGmFTHugonxqGUUuoknNk01BZIr/I6w7HslInIFBFJFJHErKyssxKcUkopS6PoLDbGzDLGJBhjEiIiIlwdjlJKNSnOTASZQHSV11GOZUoppRoQZyaCdUBnEWkvIj7A9cACJ36eUkqp0+C0RGCMsQH3AN8B24DPjDFbReQZERkNICL9RSQDGAe8KSJbnRWPUkqpmjlz1BDGmEXAomrLnqjyfB1Wk5FSSikXaRSdxUoppZxHE4FSSrk5TQRKKeXmNBEopZSb00SglFJuThOBUkq5OU0ESinl5jQRKKWUm9NEoJRSbk4TgVJKuTlNBEop5eY0ESillJvTRKCUUm5OE4FSSrk5TQRKKeXmNBEopZSb00SglFJuThOBUkq5OU0ESinl5pyaCERkpIjsEJHdIjKthvW+IvKpY/1aEYl1ZjxKKaV+y2mJQEQ8gZnA5UAccIOIxFXbbDKQa4zpBEwH/u6seJRSStXMmVcEA4DdxpgUY0wZ8Akwpto2Y4D3Hc/nAsNFRJwYk1JKqWq8nLjvtkB6ldcZwMDatjHG2EQkHwgDjlTdSESmAFMcLwtEZMdpxhRefd+NlB5Hw6LH0bDocdSsXW0rnJkIzhpjzCxg1pnuR0QSjTEJZyEkl9LjaFj0OBoWPY5T58ymoUwgusrrKMeyGrcRES8gCMh2YkxKKaWqcWYiWAd0FpH2IuIDXA8sqLbNAuBWx/NrgaXGGOPEmJRSSlXjtKYhR5v/PcB3gCfwrjFmq4g8AyQaYxYA7wD/EZHdQA5WsnCmM25eaiD0OBoWPY6GRY/jFIl+AVdKKfemdxYrpZSb00SglFJuzm0SQV3lLhoqEXlXRA6LyJYqy0JF5HsR2eX4GeLKGOtDRKJFZJmIJIvIVhG517G80RyLiPiJyM8i8ovjGJ52LG/vKJGy21EyxcfVsdaHiHiKyAYRWeh43eiOQ0RSRWSziGwUkUTHskbzN3WciASLyFwR2S4i20Rk8Lk8DrdIBPUsd9FQzQZGVls2DVhijOkMLHG8buhswJ+NMXHAIOBux79BYzqWUmCYMaY30AcYKSKDsEqjTHeUSsnFKp3SGNwLbKvyurEexyXGmD5Vxtw3pr+p42YA3xpjugK9sf5dzt1xGGOa/AMYDHxX5fUjwCOujusU4o8FtlR5vQNo7XjeGtjh6hhP45i+BEY01mMB/IH1WHfLHwG8HMtP+FtrqA+s+3qWAMOAhYA00uNIBcKrLWtUf1NY90/txTF4xxXH4RZXBNRc7qKti2I5GyKNMQcczw8Cka4M5lQ5qszGA2tpZMfiaE7ZCBwGvgf2AHnGGJtjk8byt/Uy8DBQ4XgdRuM8DgP8T0SSHKVooJH9TQHtgSzgPUdT3dsiEsA5PA53SQRNlrG+LjSaMcAi0hyYB9xnjDladV1jOBZjjN0Y0wfrG/UAoKuLQzplIjIKOGyMSXJ1LGfBBcaYvljNvneLyEVVVzaGvyms+7n6Aq8bY+KBQqo1Azn7ONwlEdSn3EVjckhEWgM4fh52cTz1IiLeWElgjjHmv47FjfJYjDF5wDKsJpRgR4kUaBx/W+cDo0UkFasq8DCsNurGdhwYYzIdPw8D87GSc2P7m8oAMowxax2v52IlhnN2HO6SCOpT7qIxqVqa41as9vYGzVFe/B1gmzHmX1VWNZpjEZEIEQl2PG+G1cexDSshXOvYrEEfA4Ax5hFjTJQxJhbr/8JSY8wEGtlxiEiAiAQefw5cBmyhEf1NARhjDgLpItLFsWg4kMy5PA5Xd5Scww6ZK4CdWG26j7k6nlOI+2PgAFCO9c1hMlZ77hJgF7AYCHV1nPU4jguwLm03ARsdjysa07EAvYANjmPYAjzhWN4B+BnYDXwO+Lo61lM4pqHAwsZ4HI54f3E8th7/f92Y/qaqHEsfINHxt/UFEHIuj0NLTCillJtzl6YhpZRStdBEoJRSbk4TgVJKuTlNBEop5eY0ESillJvTRKDcmojYHZUrjz/OWmEvEYmtWjW2HtsHiMhix/OfqtzcpZRT6R+acnfFxioZ0RAMBlY7yg0Xml/r/ijlVHpFoFQNHHXu/+Godf+ziHRyLI8VkaUisklElohIjGN5pIjMd8xV8IuIDHHsylNE3nLMX/A/xx3J1T+ro6OQ3YfAjUAS0NtxhdLyHB2ycmOaCJS7a1ataWh8lXX5xpiewL+xqnUCvAq8b4zpBcwBXnEsfwVYbqy5Cvpi3ekK0BmYaYzpDuQB11QPwBizx3FVkoRVK+d9YLKxauw39Do5qgnQO4uVWxORAmNM8xqWp2JNQpPiKJZ30BgTJiJHsGrElzuWHzDGhItIFhBljCmtso9Y4HtjTSyCiPwF8DbGPFdLLOuMMf1FZB5wrzEm4ywfrlI10isCpWpnanl+KkqrPLdTQ7+ciLzh6FTu7GgiGgksFJH7T/MzlTolmgiUqt34Kj9XO56vwqrYCTAB+NHxfAlwF1ROXhNU3w8xxkwFngaeBa4CvnY0C00/s/CVqh8dNaTcXTPHt/DjvjXGHB9CGiIim7C+1d/gWPZHrJmkHsKaVWqSY/m9wCwRmYz1zf8urKqx9XUx8AFwIbD8tI5EqdOkfQRK1cDRR5BgjDni6liUcjZtGlJKKTenVwRKKeXm9IpAKaXcnCYCpZRyc5oIlFLKzWkiUEopN6eJQCml3Nz/Ax62nNECrvoyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnWBPTdb_9gE",
        "outputId": "e9034e0d-1783-4b6e-b0fe-84fade4ee8bc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'masked_accuracy', 'masked_loss', 'val_loss', 'val_masked_accuracy', 'val_masked_loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "wBztbf9_2jI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Model -----------------------------------\n",
        "model.save(dataLocation+'NLP_Eng_to_Tel_Encoder_Decoder_V05_attention_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9v4dGgU2gsX",
        "outputId": "67d82e1d-c912-4bf7-a9f5-b7bd0dcf250e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f7d14e89be0>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_3_layer_call_fn, embedding_3_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn, embedding_4_layer_call_and_return_conditional_losses while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Prediction**"
      ],
      "metadata": {
        "id": "hsdK_X9k2n7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "@Translator.add_method\n",
        "def translate(self, texts, *,max_length=50, temperature=0.0):\n",
        "    # Encoding : PreProcess the input texts\n",
        "    context = self.encoder.convert_input(texts)\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "    # Inference Stage : Setup the loop inputs\n",
        "    tokens = []\n",
        "    attention_weights = []\n",
        "    next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "    # Decoding: \n",
        "    for _ in range(max_length):\n",
        "        # Generate the next token\n",
        "        next_token, done, state = self.decoder.get_next_token(\n",
        "            context, next_token, done, state, temperature)\n",
        "\n",
        "        # Collect the generated tokens\n",
        "        tokens.append(next_token)\n",
        "        attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "            break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)  # t*[(batch 1)] -> (batch, t)\n",
        "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "7NNzn72B2gv4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S63zge7KmVzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Testing**"
      ],
      "metadata": {
        "id": "vYC2e9Rz2qLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================================================================\n",
        "# Testing\n",
        "# ================================================================================================================================================\n",
        "test_source = input_texts[100001:]\n",
        "test_target = target_texts[100001:]\n",
        "\n",
        "print(test_source[159])\n",
        "print(test_target[159])\n",
        "print(len(test_source))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSNYjCs22s3j",
        "outputId": "51858c57-b706-4c62-dd41-fcbb68ee3c2a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know why Tom didn't come.\n",
            "టామ్ ఎందుకు రాలేదో నాకు తెలియదు.\n",
            "\n",
            "55797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElueubeGPYUx",
        "outputId": "523a49d5-e95f-4c45-da1d-24a760065075"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55797"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BleuScore**"
      ],
      "metadata": {
        "id": "BJGI9nE83Gn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##bleuscore for 10000 records of test data\n",
        "from datetime import datetime\n",
        "startTime=datetime.now()\n",
        "actualEngData = []\n",
        "actualTelData = []\n",
        "predTelData = []\n",
        "bleuScore=0\n",
        "n=10000\n",
        "for i in range(n):\n",
        "    actualEngData.append(test_source[i])\n",
        "    actualTelData.append(test_target[i])\n",
        "    predTelData.append(model.translate([test_source[i]])[0].numpy().decode())\n",
        "for i in range(n):\n",
        "  #predTelData.append(model.translate([actualEngData[i]])[0].numpy().decode())\n",
        "  bleuScore += nltk.translate.bleu_score.sentence_bleu(actualTelData[i], predTelData[i],weights=[1]) #weights=[4]\n",
        "total_bleuscore =bleuScore/n\n",
        "endTime=datetime.now()\n",
        "print(f\"number of test records:{n};bleuSCore:{total_bleuscore}\")\n",
        "endTime=endTime-startTime\n",
        "print(\"code running time\",endTime)\n"
      ],
      "metadata": {
        "id": "1W3nbxfELvPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b77383a-a2be-497f-9928-7cc6210156c1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of test records:10000;bleuSCore:0.4807346976265426\n",
            "code running time 2022-12-10 05:41:44.585863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the predictions\n",
        "startTime=datetime.now()\n",
        "bleuScore=0\n",
        "n=15\n",
        "for i in range(n):\n",
        "    print(\"english_source\",actualEngData[i])\n",
        "    print(\"actual_telugu\",actualTelData[i])\n",
        "    print(\"predTelData\",predTelData[i])\n",
        "    print(\"==========================\")\n",
        "    bleuScore += nltk.translate.bleu_score.sentence_bleu(actualTelData[i], predTelData[i],weights=[1])\n",
        "total_bleuscore =bleuScore/n\n",
        "endTime=datetime.now()\n",
        "print(f\"number of test records:{n};bleuSCore:{total_bleuscore}\")\n",
        "print(\"code running time\",endTime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf_5hYd7KSSX",
        "outputId": "3869ed9f-4a59-40e5-9c80-8acab7f4266c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_source When I was a child, I believed in Santa Claus.\n",
            "actual_telugu నేను చిన్నతనంలో, శాంతా క్లాజ్‌ను నమ్మాను.\n",
            "\n",
            "predTelData నేను చిన్నతనంలో, నేను వయోలిన్ [UK] \n",
            "==========================\n",
            "english_source Don't you know her name?\n",
            "actual_telugu ఆమె పేరు మీకు తెలియదా?\n",
            "\n",
            "predTelData ఆమె పేరు మీకు తెలుసా? \n",
            "==========================\n",
            "english_source Tom brought Mary to our party.\n",
            "actual_telugu టామ్ మేరీని మా పార్టీకి తీసుకువచ్చాడు.\n",
            "\n",
            "predTelData టామ్ మేరీ మా పార్టీకి తెచ్చాడు. \n",
            "==========================\n",
            "english_source I'm sorry. I forgot about this.\n",
            "actual_telugu నన్ను క్షమించండి.\n",
            "\n",
            "predTelData నేను క్షమించండి, నేను దీని గురించి మర్చిపోయాను. \n",
            "==========================\n",
            "english_source If I weren't poor, I'd buy that car.\n",
            "actual_telugu నేను పేదవాడు కాకపోతే, నేను ఆ కారు కొంటాను.\n",
            "\n",
            "predTelData నేను ఆ [UK] [UK] సమాధానం కొంటాను. \n",
            "==========================\n",
            "english_source Tom is afraid of big dogs.\n",
            "actual_telugu టామ్ పెద్ద కుక్కలకు భయపడతాడు.\n",
            "\n",
            "predTelData టామ్ పెద్ద కుక్కలకు భయపడతాడు. \n",
            "==========================\n",
            "english_source That guy is a party pooper.\n",
            "actual_telugu ఆ వ్యక్తి పార్టీ పూపర్.\n",
            "\n",
            "predTelData ఆ వ్యక్తి పార్టీ [UK] \n",
            "==========================\n",
            "english_source You're going to be very proud of me.\n",
            "actual_telugu మీరు నా గురించి చాలా గర్వపడతారు.\n",
            "\n",
            "predTelData మీరు నా గురించి చాలా [UK] \n",
            "==========================\n",
            "english_source Don't listen to Tom.\n",
            "actual_telugu టామ్ మాట వినవద్దు.\n",
            "\n",
            "predTelData టామ్ మాట వినవద్దు. \n",
            "==========================\n",
            "english_source Tom didn't mention Mary at all.\n",
            "actual_telugu టామ్ మేరీ గురించి అస్సలు ప్రస్తావించలేదు.\n",
            "\n",
            "predTelData టామ్ మేరీ అస్సలు మాట్లాడలేదు. \n",
            "==========================\n",
            "english_source Tom is beginning to lose his hearing.\n",
            "actual_telugu టామ్ తన వినికిడిని కోల్పోవడం ప్రారంభించాడు.\n",
            "\n",
            "predTelData టామ్ తన [UK] ప్రారంభించాడు. \n",
            "==========================\n",
            "english_source I'm dying for frozen yogurt.\n",
            "actual_telugu నేను స్తంభింపచేసిన పెరుగు కోసం చనిపోతున్నాను.\n",
            "\n",
            "predTelData నేను చాలా [UK] [UK] [UK] \n",
            "==========================\n",
            "english_source Tom is sneezing.\n",
            "actual_telugu టామ్ తుమ్ముతున్నాడు.\n",
            "\n",
            "predTelData టామ్ [UK] \n",
            "==========================\n",
            "english_source It is really nice of you.\n",
            "actual_telugu ఇది మీకు నిజంగా బాగుంది.\n",
            "\n",
            "predTelData ఇది నిజంగా ఆనందంగా ఉంది. \n",
            "==========================\n",
            "english_source You're such a beautiful woman.\n",
            "actual_telugu మీరు అంత అందమైన మహిళ.\n",
            "\n",
            "predTelData మీరు ఇంత అందమైన స్త్రీని. \n",
            "==========================\n",
            "number of test records:15;bleuSCore:0.4560012085151404\n",
            "code running time 2022-12-10 05:42:36.281631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result = model.translate([\"Don't you know her name?\"]) # Are you still home\n",
        "result[0].numpy().decode()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hhaUK6RlJPKI",
        "outputId": "c00f67a7-f9db-45ee-8216-3f26962c5f76"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ఆమె పేరు మీకు తెలుసా? '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataLocation + 'test_source.txt', 'wb') as file:\n",
        "    pickle.dump(test_source, file)\n",
        "with open(dataLocation + 'test_target.txt', 'wb') as file:\n",
        "    pickle.dump(test_target, file)"
      ],
      "metadata": {
        "id": "huebvg4fmZvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bleuscore for 1000 records of test data\n",
        "def evaluate(actualEngData,actualTelData,n=1000):\n",
        "  predTelData=[]\n",
        "  bleuScore=0\n",
        "  for i in range(n):\n",
        "    predTelData.append(model.translate([actualEngData[i]])[0].numpy().decode())\n",
        "    bleuScore += nltk.translate.bleu_score.sentence_bleu(actualTelData[i], predTelData[i],weights=[1]) #weights=[4]\n",
        "  total_bleuscore=bleuScore/n\n",
        "  result={\"actualEngData\":actualEngData[0:n],\n",
        "          \"actualTelData\":actualTelData[0:n],\n",
        "          \"predTelData\":predTelData[0:n],\n",
        "          \"bleuScore\":total_bleuscore}\n",
        "  return result\n",
        "  "
      ],
      "metadata": {
        "id": "FCGe0OzTmrlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = evaluate(test_source,test_target,n=1000)\n",
        "\"\"\"print(result[\"actualEngData\"][0])\n",
        "print(result[\"actualTelData\"][0])\n",
        "print(result[\"predTelData\"][0])\"\"\"\n",
        "print(result[\"bleuScore\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2_8bevFwCix",
        "outputId": "ad045633-8f86-4f7f-f473-fe9e2ab9724d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43179537269719415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import pickle\n",
        "with open(dataLocation+'Bleu_Score_With_Attention', 'wb') as file:\n",
        "  pickle.dump(blueScore, file)\"\"\""
      ],
      "metadata": {
        "id": "0mGkcFQq2s9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataLocation + 'test_source.txt', 'wb') as file:\n",
        "    pickle.dump(test_source, file)\n",
        "with open(dataLocation + 'test_target.txt', 'wb') as file:\n",
        "    pickle.dump(test_target, file)"
      ],
      "metadata": {
        "id": "s-90NCEiB2pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}