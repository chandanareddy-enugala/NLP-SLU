{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MCvUGtnNgmh0",
        "fCWxCwrekBVx",
        "xtseLCYng04C"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandanareddy-enugala/NLP-SLU/blob/main/Assignment_05_V01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFeg-Zqpe6AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3350bf3-2b7d-4bf4-81e2-2f568743de60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, GRU\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from numpy import argmax\n",
        "\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "SvkvflzkJOmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining Dictionary Functions Class**"
      ],
      "metadata": {
        "id": "MCvUGtnNgmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DictionaryFunctions:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "  def addVal_to_dictKey(self, D, k, val=1): # Inputs: Dictionary, Key, Value; Ouput: Dictionary (Updated)\n",
        "    if k in D:\n",
        "      if type(val)==int:\n",
        "        D[k] += val\n",
        "      elif (type(val)==str):\n",
        "        D[k].append(val)\n",
        "    else:\n",
        "      if type(val)==int:\n",
        "        D[k] = val\n",
        "      elif (type(val)==str):\n",
        "        D[k] = [val]\n",
        "    return D\n",
        "\n",
        "  def find_probs_of_dict(self, D):\n",
        "    total = 0\n",
        "    for key in D.keys():\n",
        "      total += D[key]\n",
        "    for key in D.keys():\n",
        "      D[key] /= total\n",
        "    return D \n",
        "\n",
        "  def get_dict_from_list(self, L):\n",
        "    D = {}\n",
        "    for char in L:\n",
        "      if char in D:\n",
        "        D[char] += 1\n",
        "      else:\n",
        "        D[char] = 1\n",
        "    return D\n",
        "\n",
        "  def max_of_dict(self, D):  \n",
        "    maxProb = 0\n",
        "    maxKey = ''\n",
        "    for key, probVal in D.items():\n",
        "      if probVal>maxProb:\n",
        "        maxProb = probVal\n",
        "        maxKey = key\n",
        "    return (maxKey, maxProb)"
      ],
      "metadata": {
        "id": "TsMUF__fmwzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Dataset**"
      ],
      "metadata": {
        "id": "fCWxCwrekBVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filePath):\n",
        "  data_cwe = open(filePath, 'r').read().lower()\n",
        "  return data_cwe"
      ],
      "metadata": {
        "id": "5gVTam4ukEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing Model Preparation**"
      ],
      "metadata": {
        "id": "HvS8ncVwgtFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Language_Translation_Model:\n",
        "  def __init__(self, lang=\"\") -> None:\n",
        "    self.lang = lang\n",
        "    self.data = pd.DataFrame(columns=['sentence'])\n",
        "    self.all_Unique_Characters = None\n",
        "    self.length_all_Unique_Characters = None\n",
        "    self.length_max_sentence = None\n",
        "    self.sentenceArray_to_OHE = None\n",
        "    self.char_to_num = None\n",
        "    self.num_to_char = None\n",
        "    # self.ASCII_Chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'\n",
        "  \n",
        "  def sentence_to_array(self, sentence):\n",
        "    sentenceArray = [self.char_to_num[char] for char in sentence]\n",
        "    #padding = [0 for _ in range(self.length_all_Unique_Characters-len(sentenceArray))]\n",
        "    #sentenceArray = np.array(sentenceArray+padding)\n",
        "    return sentenceArray\n",
        "  \n",
        "  def sentenceArray_to_OHE1(self, sentenceArray):\n",
        "    sentenceArray_OHE = to_categorical(sentenceArray)\n",
        "    (req_rows, req_cols) = (self.length_max_sentence, self.length_all_Unique_Characters)\n",
        "    (actual_rows, actual_cols) = sentenceArray_OHE.shape\n",
        "    sentenceArray_OHE = np.concatenate((sentenceArray_OHE, np.zeros((req_rows-actual_rows, actual_cols), dtype='float32')), axis=0)\n",
        "    sentenceArray_OHE = np.concatenate((sentenceArray_OHE, np.zeros((req_rows, req_cols-actual_cols), dtype='float32')), axis=1)\n",
        "    return sentenceArray_OHE\n",
        "\n",
        "  def OHE_to_sentenceArray(self, sentence_array_OHE):\n",
        "    sentenceArray = []\n",
        "    for OHE in sentence_array_OHE:\n",
        "      if sum(OHE)!=0:\n",
        "        sentenceArray.append(argmax(OHE))\n",
        "    return sentenceArray\n",
        "  \n",
        "  def preprocess_data(self, text):\n",
        "    # Cleaning --------------------------\n",
        "    text = text.replace(\"\\n\", \" \") \n",
        "    for char in [' .', ' ,', ' ;', ' ?', ' !', '( ', ' )']:\n",
        "      text = text.replace(char, char.strip())\n",
        "    text = text.replace(\"<s>\", \"\")\n",
        "    \n",
        "    # =========================== CHARACTERS ===========================\n",
        "    # Unique Characters -----------------\n",
        "    self.all_Unique_Characters = list(set(text.replace(\"</s>\", \"\")))\n",
        "    self.all_Unique_Characters.sort()\n",
        "    \n",
        "    # Max Length of Unique Characters ---\n",
        "    self.length_all_Unique_Characters = len(self.all_Unique_Characters)\n",
        "    \n",
        "    # Preparing Character to Number and vice-versa -----\n",
        "    self.char_to_num = {char:num for num, char in enumerate(self.all_Unique_Characters)}\n",
        "    self.num_to_char = {val:key for key, val in self.char_to_num.items()}\n",
        "\n",
        "    # =========================== SENTENCES ===========================\n",
        "    # Sentences -------------------------\n",
        "    sentences = text.split(\"</s>\")[:-1]\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "    \n",
        "    # Max Length of Sentences -----------\n",
        "    self.length_max_sentence = max([len(sentence) for sentence in sentences])\n",
        "    \n",
        "    # Preparing OHE Array Variable ------\n",
        "    self.sentenceArray_to_OHE = np.zeros((self.length_max_sentence, self.length_all_Unique_Characters), dtype='float32')\n",
        "    \n",
        "    # =========================== DATAFRAME ===========================\n",
        "    # Storing sentences in dataframe ----\n",
        "    self.data['sentence'] = sentences\n",
        "    # Converting Sentence to Array Numbers ----\n",
        "    self.data['sentence_array'] = self.data['sentence'].apply(lambda x: self.sentence_to_array(x))\n",
        "    # Converting Array Numbers to One-Hot-Encoding (OHE) ----\n",
        "    self.data['sentence_array_OHE'] = self.data['sentence_array'].apply(lambda x: self.sentenceArray_to_OHE1(x))\n",
        "\n",
        "    return self.data"
      ],
      "metadata": {
        "id": "0JI-c16BTH7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/train-source.txt\"\n",
        "train_input_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "yi8TCu-bpAMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Input_LTM = Language_Translation_Model()\n",
        "Input_data = Input_LTM.preprocess_data(train_input_data[0:10000])\n",
        "Input_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "4s2tKcYwXn1k",
        "outputId": "0ba8e5f7-344d-41cb-9dea-02e3774943e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  cinnte go leór, thiocfadh dóbhtha bás a fhaghá...   \n",
              "1  (bhí sé follasach go rabh an poll sin ag foscl...   \n",
              "2  ) d'fhéadfadh siad bás ' fhagháil ar a bhruach...   \n",
              "3  thiocfadh dóbhtha fosta lámh a chur ina mbás f...   \n",
              "4  ' na dhiaidh sin, bhí rud éigin do-chreidte ag...   \n",
              "\n",
              "                                      sentence_array  \\\n",
              "0  [16, 22, 26, 26, 31, 18, 0, 20, 27, 0, 24, 18,...   \n",
              "1  [4, 15, 21, 36, 0, 30, 35, 0, 19, 27, 24, 24, ...   \n",
              "2  [5, 0, 17, 3, 19, 21, 35, 14, 17, 19, 14, 17, ...   \n",
              "3  [31, 21, 22, 27, 16, 19, 14, 17, 21, 0, 17, 37...   \n",
              "4  [3, 0, 26, 14, 0, 17, 21, 22, 14, 22, 17, 21, ...   \n",
              "\n",
              "                                  sentence_array_OHE  \n",
              "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "1  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...  \n",
              "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "4  [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f77a624a-8687-4df2-8995-b334bab14274\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_array</th>\n",
              "      <th>sentence_array_OHE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cinnte go leór, thiocfadh dóbhtha bás a fhaghá...</td>\n",
              "      <td>[16, 22, 26, 26, 31, 18, 0, 20, 27, 0, 24, 18,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(bhí sé follasach go rabh an poll sin ag foscl...</td>\n",
              "      <td>[4, 15, 21, 36, 0, 30, 35, 0, 19, 27, 24, 24, ...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>) d'fhéadfadh siad bás ' fhagháil ar a bhruach...</td>\n",
              "      <td>[5, 0, 17, 3, 19, 21, 35, 14, 17, 19, 14, 17, ...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thiocfadh dóbhtha fosta lámh a chur ina mbás f...</td>\n",
              "      <td>[31, 21, 22, 27, 16, 19, 14, 17, 21, 0, 17, 37...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>' na dhiaidh sin, bhí rud éigin do-chreidte ag...</td>\n",
              "      <td>[3, 0, 26, 14, 0, 17, 21, 22, 14, 22, 17, 21, ...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f77a624a-8687-4df2-8995-b334bab14274')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f77a624a-8687-4df2-8995-b334bab14274 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f77a624a-8687-4df2-8995-b334bab14274');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/train-target.txt\"\n",
        "train_target_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "jEjY7j6zFB8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Output_LTM = Language_Translation_Model()\n",
        "Output_data = Output_LTM.preprocess_data(train_target_data[0:10000])\n",
        "Output_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "jW3-c8D04x5P",
        "outputId": "32ffd58e-a33e-40bc-8aaa-634d04b47e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  cinnte go leor, thiocfadh dóibh bás a fháil ar...   \n",
              "1  bhí sé follasach go raibh an poll sin ag foscl...   \n",
              "2  d'fhéadfadh siad bás a fháil ar a bhruach agus...   \n",
              "3  thiocfadh dóibh fosta lámh a chur ina mbás féi...   \n",
              "4  ina dhiaidh sin bhí rud éigin dochreidte agus ...   \n",
              "\n",
              "                                      sentence_array  \\\n",
              "0  [15, 21, 25, 25, 30, 17, 0, 19, 26, 0, 23, 17,...   \n",
              "1  [14, 20, 35, 0, 29, 34, 0, 18, 26, 23, 23, 13,...   \n",
              "2  [16, 2, 18, 20, 34, 13, 16, 18, 13, 16, 20, 0,...   \n",
              "3  [30, 20, 21, 26, 15, 18, 13, 16, 20, 0, 16, 36...   \n",
              "4  [21, 25, 13, 0, 16, 20, 21, 13, 21, 16, 20, 0,...   \n",
              "\n",
              "                                  sentence_array_OHE  \n",
              "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d02bebe5-8877-4ad0-b683-f9db23ba8583\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_array</th>\n",
              "      <th>sentence_array_OHE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cinnte go leor, thiocfadh dóibh bás a fháil ar...</td>\n",
              "      <td>[15, 21, 25, 25, 30, 17, 0, 19, 26, 0, 23, 17,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bhí sé follasach go raibh an poll sin ag foscl...</td>\n",
              "      <td>[14, 20, 35, 0, 29, 34, 0, 18, 26, 23, 23, 13,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d'fhéadfadh siad bás a fháil ar a bhruach agus...</td>\n",
              "      <td>[16, 2, 18, 20, 34, 13, 16, 18, 13, 16, 20, 0,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thiocfadh dóibh fosta lámh a chur ina mbás féi...</td>\n",
              "      <td>[30, 20, 21, 26, 15, 18, 13, 16, 20, 0, 16, 36...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ina dhiaidh sin bhí rud éigin dochreidte agus ...</td>\n",
              "      <td>[21, 25, 13, 0, 16, 20, 21, 13, 21, 16, 20, 0,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d02bebe5-8877-4ad0-b683-f9db23ba8583')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d02bebe5-8877-4ad0-b683-f9db23ba8583 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d02bebe5-8877-4ad0-b683-f9db23ba8583');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.array([record for record in Input_data['sentence_array_OHE']])\n",
        "decoder_input_data = np.array([np.concatenate((np.zeros((record.shape[0], 1), dtype='float32'), record[:, 1:]), axis=1) for record in Output_data['sentence_array_OHE']])\n",
        "decoder_target_data = np.array([record for record in Output_data['sentence_array_OHE']])"
      ],
      "metadata": {
        "id": "NyNCet3HIGxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Preparation**"
      ],
      "metadata": {
        "id": "9GtOnbg7lMMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs=1\n",
        "latent_dim=256\n",
        "num_samples=10000"
      ],
      "metadata": {
        "id": "wVjsuqgdlYHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None, Input_LTM.length_all_Unique_Characters))\n",
        "encoder = LSTM(latent_dim, return_state=True) # latent_dim = 256\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "vaD-BSs1jgde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, Output_LTM.length_all_Unique_Characters))\n",
        "\n",
        "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(Output_LTM.length_all_Unique_Characters, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "lFkEx7wpiWg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Model ------------------\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Training Model ------------------\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], \n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-__pyVyfmlv2",
        "outputId": "f642f742-22b3-469c-f04e-0985afc015b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step - loss: 1.2344 - accuracy: 0.3334 - val_loss: 1.2413 - val_accuracy: 0.7151\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae9f2d26d0>"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictions**"
      ],
      "metadata": {
        "id": "91-KmQHbOy3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_states_inputs = [Input(shape=(latent_dim,)), Input(shape=(latent_dim,))]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "t0RKQhnIJMNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "2Fl-wRoLSCNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_seq = data.loc[0, 'sentence']\n",
        "print(test_input_seq)\n",
        "encoder_model.predict(test_input_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "JiZG0DmCO1sy",
        "outputId": "a9c1e72a-abf0-4530-e158-5616d1140b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cinnte go leór, thiocfadh dóbhtha bás a fhagháil ar imeall an phuill udaí.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-254-1fe8052c82d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_input_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "kVe8nuwmJTR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('s2s.h5')"
      ],
      "metadata": {
        "id": "ylpEx5jUJMRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oNwYliM8JV4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PjAh5UzJV6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_AXscMyOJV-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X82NZEmYJWA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rough Work**"
      ],
      "metadata": {
        "id": "mr9YWwOljm99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
        "#enc.n_values_\n",
        "# array([2, 3, 4])\n",
        "enc.feature_indices_\n",
        "# array([0, 2, 5, 9], dtype=int32)\n",
        "enc.transform([[0, 1, 1]]).toarray()\n",
        "# array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "sD1o6iIutbim",
        "outputId": "97d95efc-4704-46a0-ba41-580359a77175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-19fa608afa3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#enc.n_values_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# array([2, 3, 4])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_indices_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# array([0, 2, 5, 9], dtype=int32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'feature_indices_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8UdJ55utbl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allUniqueCharacters = []\n",
        "for sentence in input_texts:\n",
        "  allUniqueCharacters += list(sentence)\n",
        "allUniqueCharacters = list(set(allUniqueCharacters))\n",
        "len(allUniqueCharacters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxXHhw5ypIWu",
        "outputId": "f1183392-9aa7-42b2-90be-c0e5f53163ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = {char:num for num, char in enumerate(allUniqueCharacters, start=1)}"
      ],
      "metadata": {
        "id": "eJdAB6pupIaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sent_length = max([len(sent) for sent in  input_texts])"
      ],
      "metadata": {
        "id": "C60m7yzrqOQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentenceToArray(x):\n",
        "  array = [char_to_num[char] for char in x]\n",
        "  array += [0 for _ in range(max_sent_length - len(array))]\n",
        "  return array"
      ],
      "metadata": {
        "id": "Ql_mbaVXp3Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LTM1 = Language_Translation_Model()\n",
        "input_text_array = pd.Series(input_texts).apply(lambda x: sentenceToArray(x))\n",
        "input_text_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY7KMUOooYm8",
        "outputId": "1bdbd77f-8810-4c0a-8e05-1a8c0e71f2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [7, 68, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
              "1       [27, 22, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "2       [27, 22, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "3       [50, 3, 6, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
              "4       [50, 3, 6, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
              "                              ...                        \n",
              "9995    [71, 70, 10, 12, 8, 68, 3, 12, 22, 6, 15, 3, 7...\n",
              "9996    [71, 70, 10, 12, 8, 68, 3, 12, 22, 6, 15, 3, 7...\n",
              "9997    [71, 70, 10, 12, 8, 68, 3, 12, 22, 6, 15, 3, 7...\n",
              "9998    [71, 70, 10, 12, 8, 68, 3, 12, 22, 6, 15, 3, 7...\n",
              "9999    [71, 70, 10, 12, 8, 68, 3, 12, 22, 6, 15, 3, 7...\n",
              "Length: 10000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentenceArray_to_OHE1(sentenceArray):\n",
        "  sentenceArray_OHE = to_categorical(sentenceArray)\n",
        "  return sentenceArray_OHE"
      ],
      "metadata": {
        "id": "yHq-biBTqrMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_OHE = input_text_array.apply(lambda x: sentenceArray_to_OHE1(x))"
      ],
      "metadata": {
        "id": "iRqI6Eveq_VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_OHE[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVJVfi4b6REx",
        "outputId": "87f6d8b6-5355-4ba8-a7be-9ec207d9c047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input_text_OHE[999]\n",
        "L0 = [argmax(char) for char in input_text_OHE[999]]\n",
        "print(L0)\n",
        "print([num_to_char0[num] for num in L0 if num!=0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jh8JLHdq_Y3",
        "outputId": "6315539b-29d1-40e5-ccbc-17a8b16b0856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[66, 10, 12, 29, 39, 22, 61, 10, 33, 16, 0, 0, 0, 0, 0, 0]\n",
            "['W', 'e', ' ', 'w', 'a', 'i', 't', 'e', 'd', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char0 = {num:char for char, num in char_to_num.items()}\n",
        "num_to_char0[66]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Sh6xxCTeutIC",
        "outputId": "bf7b8e48-916e-47d7-e7da-64ba7d832e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'W'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argmax(encoder_input_data[999][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-vSGtmuuKOb",
        "outputId": "0f7930dd-1971-4448-fe27-0d51f5616030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ATGb3i26c75",
        "outputId": "5b28362e-38cb-4a74-c355-08b41557848b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input_text_OHE[999]\n",
        "L1 = [argmax(char) for char in encoder_input_data[999]]\n",
        "print(L1)\n",
        "print([num_to_char1[num] for num in L1 if num!=0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5g3ZY29v5Rj",
        "outputId": "7224ba8b-b4c0-4e0e-8241-3a616c8a48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[42, 48, 0, 66, 44, 52, 63, 48, 47, 8, 0, 0, 0, 0, 0, 0]\n",
            "['W', 'e', 'w', 'a', 'i', 't', 'e', 'd', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char1[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lTYmegjSurCc",
        "outputId": "c8e4b323-8702-4ebf-e668-a43b917fcc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'W'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char1 = {num:char for char, num in input_token_index.items()}"
      ],
      "metadata": {
        "id": "PEAGmpihuKR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(input_text_array[9999])\n",
        "#input_text_OHE[999]\n",
        "L0 = [argmax(char) for char in input_text_OHE[999]]\n",
        "print(L0)\n",
        "print([num_to_char0[num] for num in L0 if num!=0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6tBi5TboYqd",
        "outputId": "14a9b650-0d41-4294-df16-e2052ad53cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/fra.txt\"\n",
        "with open(filePath, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')"
      ],
      "metadata": {
        "id": "8bgJ_kiln3Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples=10000\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    \n",
        "    \n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "            \n",
        "            \n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "A-emEEp4YIQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kdn4QBVvogEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "metadata": {
        "id": "Qep0We5fYITr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2iHroMkc7Vn",
        "outputId": "34932263-caa9-436d-91a5-14d96f960e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "metadata": {
        "id": "B0fp4fUVc-Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            '''\n",
        "            decoder_target_data will be ahead by one timestep\n",
        "            and will not include the start character.\n",
        "            \n",
        "            '''\n",
        "            \n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "metadata": {
        "id": "TQGHvlzeKUDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t, char in enumerate(target_texts[1000]):\n",
        "  print(t, char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv4gUplaGt9E",
        "outputId": "5073ed43-bcd7-4703-aa6c-0d9be162136a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \t\n",
            "1 N\n",
            "2 o\n",
            "3 u\n",
            "4 s\n",
            "5  \n",
            "6 s\n",
            "7 o\n",
            "8 m\n",
            "9 m\n",
            "10 e\n",
            "11 s\n",
            "12  \n",
            "13 a\n",
            "14 l\n",
            "15 l\n",
            "16 é\n",
            "17 s\n",
            "18  \n",
            "19 à\n",
            "20  \n",
            "21 p\n",
            "22 i\n",
            "23 e\n",
            "24 d\n",
            "25 .\n",
            "26 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts[1000], target_texts[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVj3QbYx90a-",
        "outputId": "545ba3a3-f63b-40c5-e688-6fcc112dbeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('We walked.', '\\tNous sommes allés à pied.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data[1000].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4oh7QALhgoD",
        "outputId": "9e7ce4b6-a0d7-48f8-93b4-93cff6a039e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 71)"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([argmax(row) for row in encoder_input_data[1000]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pSczvwr9r72",
        "outputId": "d5b99415-767e-4432-9ed0-83a66bd26b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[42, 48, 0, 66, 44, 55, 54, 48, 47, 8, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data[1000].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKVyxAnC9CNq",
        "outputId": "0420b886-a870-437d-d3ed-c23fa76d09f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([argmax(row) for row in decoder_input_data[2000]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWQffpST9IDm",
        "outputId": "41a75e7b-3243-4669-f52f-84d89e01a039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 26, 44, 52, 63, 48, 62, 10, 55, 48, 2, 46, 58, 56, 56, 48, 2, 52, 55, 2, 49, 44, 64, 63, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target_data[1000].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf7Eh8FF9AZn",
        "outputId": "67187236-8e7e-436c-c67f-b82dfc6b8da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([argmax(row) for row in decoder_target_data[2000]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HvKxCDH9A7i",
        "outputId": "146cbe9c-ae8b-4388-bd68-aea8728a39e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26, 44, 52, 63, 48, 62, 10, 55, 48, 2, 46, 58, 56, 56, 48, 2, 52, 55, 2, 49, 44, 64, 63, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data[0][:, 1:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfezMk0Fc3Jp",
        "outputId": "df3d5764-ce5e-4a63-d41f-bb557c72625b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 70)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\" ljflaj \".strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gykAVBiETzJO",
        "outputId": "88aaf1d2-aa06-4fe1-a7eb-2174cbdd9206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ljflaj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=15\n",
        "LM_15 = Language_Model(n, 'swe')"
      ],
      "metadata": {
        "id": "8QcATF39q3nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data_sentences = LM_15.get_Sentences_from_Text(train_input_data)"
      ],
      "metadata": {
        "id": "mzo2he87q-vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\".join(train_input_data_sentences[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di1lPgEtrHxl",
        "outputId": "33391a88-60a7-4f85-8275-d7f2e5aadae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>\n",
            "cinnte\n",
            "go\n",
            "leór\n",
            ",\n",
            "thiocfadh\n",
            "dóbhtha\n",
            "bás\n",
            "a\n",
            "fhagháil\n",
            "ar\n",
            "imeall\n",
            "an\n",
            "phuill\n",
            "udaí\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data[0:80]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wXfEPzhcrS5N",
        "outputId": "3da9eeb8-f9d7-4f43-c9ad-f54bdac40b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>\\ncinnte\\ngo\\nleór\\n,\\nthiocfadh\\ndóbhtha\\nbás\\na\\nfhagháil\\nar\\nimeall\\nan\\nphuill\\nudaí\\n.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Language Model : SWE**"
      ],
      "metadata": {
        "id": "xtseLCYng04C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-gram Model**"
      ],
      "metadata": {
        "id": "WY8iItY1hBBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startTime = datetime.now()\n",
        "\n",
        "LM_5 = Language_Model(5)\n",
        "LM_5.fit(train_data)\n",
        "\n",
        "endTime = datetime.now()\n",
        "print(\"\\n\")\n",
        "print(f\"Code running time : {endTime-startTime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohz7wZXCBEy5",
        "outputId": "cab13df6-6caf-4ad8-f9ed-59502ab2966b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n",
            "\n",
            "\n",
            "Code running time : 0:00:01.562456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log2loss = LM_5.evaluate(train_data)\n",
        "print(log2loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtNRbIftfm1d",
        "outputId": "fdf2f69c-580e-4d26-f95d-c67bbeafd762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.209649119639972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log2loss = LM_5.evaluate(test_data)\n",
        "print(log2loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhBKsL61WX5j",
        "outputId": "c6228588-cf6a-4bfc-d0f8-51c0fb344c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1544019103445355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "LM_5 = Language_Model(n, 'swe')\n",
        "LM_5.fit(train_data)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Training Log2Loss : {LM_5.evaluate(train_data)}\") \n",
        "print(f\"Testing Log2Loss : {LM_5.evaluate(test_data)}\") \n",
        "\n",
        "endTime = datetime.now()\n",
        "print(\"\\n\")\n",
        "print(f\"Code running time : {endTime-startTime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDMxqbjwNDnp",
        "outputId": "c29373eb-dd4e-48e1-e18b-1b26f516cf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n",
            "\n",
            "\n",
            "Training Log2Loss : 1.2688606397085775\n",
            "Testing Log2Loss : 1.206416137765356\n",
            "\n",
            "\n",
            "Code running time : 0:00:04.303345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10-gram Model**"
      ],
      "metadata": {
        "id": "TB6uqGH-hInY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "LM_10 = Language_Model(n, 'swe')\n",
        "LM_10.fit(train_data)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Training Log2Loss : {LM_10.evaluate(train_data)}\") \n",
        "print(f\"Testing Log2Loss : {LM_10.evaluate(test_data)}\") \n",
        "\n",
        "endTime = datetime.now()\n",
        "print(\"\\n\")\n",
        "print(f\"Code running time : {endTime-startTime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu_I-P9ZhPhR",
        "outputId": "2519b318-035d-4066-df1d-5aef34047a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n",
            "Training Log2Loss : 0.3780673061919561\n",
            "Testing Log2Loss : 0.27591094078507133\n",
            "\n",
            "\n",
            "Code running time : 0:00:03.806859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15-gram Model**"
      ],
      "metadata": {
        "id": "ugJdy4eDhtw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 15\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "LM_15 = Language_Model(n, 'swe')\n",
        "LM_15.fit(train_data)\n",
        "\n",
        "print(\"\\n\")\n",
        "#print(f\"Training Log2Loss : {LM_15.evaluate(train_data)}\") \n",
        "print(f\"Testing Log2Loss : {LM_15.evaluate(test_data)}\") \n",
        "\n",
        "endTime = datetime.now()\n",
        "print(\"\\n\")\n",
        "print(f\"Code running time : {endTime-startTime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnGA_k-GhetT",
        "outputId": "7d5abb4c-ccd8-4be0-d959-3d015287bef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n",
            "\n",
            "\n",
            "Testing Log2Loss : 0.06150412268756698\n",
            "\n",
            "\n",
            "Code running time : 0:00:05.202777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "XhHRCpztML55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LM_15 = Language_Model(n, 'swe')\n",
        "LM_15.fit(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDpd-3z0ME4C",
        "outputId": "3e176a7d-cdf8-4b59-d6c6-f1a34058e9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TRAINING IS COMPLETED ====\n",
            "Success: ngrams & ngrams_nextChars are stored successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Log2Loss : {LM_15.evaluate(train_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOo8YPt_MHHl",
        "outputId": "d9f43db4-2364-4fea-f5dc-bdce551d4918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Log2Loss : 0.11459748277321753\n",
            "_ngrams_Available :  603432\n",
            "_ngrams_nextChars_Available :  603431\n",
            "_ngrams_notAvailable :  0\n",
            "_ngrams_nextChars_notAvailable :  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Testing Log2Loss : {LM_15.evaluate(test_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT_hkhPSNZqC",
        "outputId": "b92b1bb3-b3a3-4fc1-fcb2-c7daf954f42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Log2Loss : 0.06150412268756698\n",
            "_ngrams_Available :  15920\n",
            "_ngrams_nextChars_Available :  13311\n",
            "_ngrams_notAvailable :  45797\n",
            "_ngrams_nextChars_notAvailable :  48406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJnnFdyDNh_O",
        "outputId": "0feb9e52-f01f-40e2-eb5f-3aae620f2a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61717"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing 2**"
      ],
      "metadata": {
        "id": "OSdEjpXEP0ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=15\n",
        "LM_15 = Language_Model(n, 'swe')\n",
        "LM_15.fit(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "yP5NzWPOPyiF",
        "outputId": "232cbe99-e328-458e-8b9e-aab538bd600d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f849d8214ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mLM_15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguage_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLM_15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-2b6de3b62875>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mall_characters_in_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# sentences = self.get_Sentences_from_Text(all_characters_in_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mstatusMessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_characters_in_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==== TRAINING IS COMPLETED ====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatusMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-2b6de3b62875>\u001b[0m in \u001b[0;36mstore_ngrams\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_char_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_char_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m       \u001b[0mngrams_nextChars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-2b6de3b62875>\u001b[0m in \u001b[0;36m_char_prob\u001b[0;34m(self, chars_List)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_char_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars_List\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mchar_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dict_from_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars_List\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mchar_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_probs_of_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchar_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-035c451faee8>\u001b[0m in \u001b[0;36mget_dict_from_list\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Log2Loss : {LM_15.evaluate(train_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft2VWvolPuXO",
        "outputId": "66843401-f6e4-4fc3-859c-47ac6552b031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Log2Loss : 11.443842603736776\n",
            "_ngrams_Available :  603432\n",
            "_ngrams_nextChars_Available :  603431\n",
            "_ngrams_notAvailable :  0\n",
            "_ngrams_nextChars_notAvailable :  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Testing Log2Loss : {LM_15.evaluate(test_data)}\") \n",
        "\n",
        "print(\"_ngrams_Available : \", len(LM_15._ngrams_Available))\n",
        "print(\"_ngrams_nextChars_Available : \", len(LM_15._ngrams_nextChars_Available))\n",
        "\n",
        "print(\"_ngrams_notAvailable : \", len(LM_15._ngrams_notAvailable))\n",
        "print(\"_ngrams_nextChars_notAvailable : \", len(LM_15._ngrams_nextChars_notAvailable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_NZRg80Pws-",
        "outputId": "94e73817-8692-4e3e-bc4d-96535b8f35ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Log2Loss : 11.48324833516333\n",
            "_ngrams_Available :  61669\n",
            "_ngrams_nextChars_Available :  61345\n",
            "_ngrams_notAvailable :  48\n",
            "_ngrams_nextChars_notAvailable :  372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhNm0pTIPuav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rough**"
      ],
      "metadata": {
        "id": "bqRhOy_6FkYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_Char_List = list(train_data)\n",
        "\n",
        "DF = DictionaryFunctions()\n",
        "train_data_Char_Dict = DF.get_dict_from_list(train_data_Char_List)\n",
        "train_data_Char_Dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWxU1n2RFl2B",
        "outputId": "f8867f6a-29bc-469b-9074-cf77b94bb717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 5446,\n",
              " 'h': 20755,\n",
              " 'i': 46266,\n",
              " 'k': 23425,\n",
              " 'a': 87267,\n",
              " 'l': 33255,\n",
              " 'e': 32796,\n",
              " ' ': 84914,\n",
              " 'v': 5778,\n",
              " 'n': 38966,\n",
              " 'o': 26873,\n",
              " 'g': 16766,\n",
              " 'f': 2446,\n",
              " 'y': 17481,\n",
              " 'w': 31352,\n",
              " 'u': 40148,\n",
              " 'b': 7463,\n",
              " \"'\": 2502,\n",
              " 'm': 25905,\n",
              " 's': 10737,\n",
              " ',': 7106,\n",
              " 'j': 1545,\n",
              " 'd': 9800,\n",
              " 't': 7034,\n",
              " '.': 5269,\n",
              " 'p': 1141,\n",
              " 'z': 8054,\n",
              " '\"': 2167,\n",
              " '!': 341,\n",
              " '?': 421,\n",
              " '-': 12,\n",
              " '\\n': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF = DictionaryFunctions()\n",
        "train_data_Char_Prob = DF.find_probs_of_dict(train_data_Char_Dict)\n",
        "train_data_Char_Prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kt2-4uuFl6E",
        "outputId": "7cf8f97d-7917-45e5-ae8e-584ba96d1f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 0.009025043418313911,\n",
              " 'h': 0.03439492768033515,\n",
              " 'i': 0.07667143936682178,\n",
              " 'k': 0.0388196184491376,\n",
              " 'a': 0.14461778626257804,\n",
              " 'l': 0.05510977210356759,\n",
              " 'e': 0.0543491230163465,\n",
              " ' ': 0.14071842394834877,\n",
              " 'v': 0.009575229686194965,\n",
              " 'n': 0.06457397022365403,\n",
              " 'o': 0.04453360113484204,\n",
              " 'g': 0.027784406527993213,\n",
              " 'f': 0.004053480756738124,\n",
              " 'y': 0.028969295629002106,\n",
              " 'w': 0.051956144188574686,\n",
              " 'u': 0.0665327659123149,\n",
              " 'b': 0.012367590714446697,\n",
              " \"'\": 0.004146283259754206,\n",
              " 'm': 0.042929443582706915,\n",
              " 's': 0.01779322276577974,\n",
              " ',': 0.011775974757719179,\n",
              " 'j': 0.00256035477071153,\n",
              " 'd': 0.016240438027814236,\n",
              " 't': 0.01165665725384136,\n",
              " '.': 0.00873172122128094,\n",
              " 'p': 0.0018908509989526575,\n",
              " 'z': 0.013346988558777128,\n",
              " '\"': 0.0035911254292115766,\n",
              " '!': 0.0005651009558657811,\n",
              " '?': 0.0006976759601744687,\n",
              " '-': 1.9886250646303147e-05,\n",
              " '\\n': 1.6571875538585954e-06}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for key in train_data_Char_Prob:\n",
        "  sum += train_data_Char_Prob[key]\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo18_aRsFl9o",
        "outputId": "026fd9fd-fe93-4f2e-d389-0fc2a3e364fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoQ6RbfcGxci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_Char_List = list(test_data)\n",
        "\n",
        "DF = DictionaryFunctions()\n",
        "test_data_Char_Dict = DF.get_dict_from_list(test_data_Char_List)\n",
        "test_data_Char_Prob = DF.find_probs_of_dict(test_data_Char_Dict)\n",
        "\n",
        "sum = 0\n",
        "for key in test_data_Char_Prob:\n",
        "  sum += test_data_Char_Prob[key]\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shSL_2Y1HFUg",
        "outputId": "d43242c8-2208-47e5-dde4-ac120fb743da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWQ-QgCWHZSr",
        "outputId": "01f9a62d-bba5-4ece-d3f6-fba116be05d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ASCII_Chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'\n",
        "all_characters_in_data = re.findall(r\"[%s]\"%ASCII_Chars, train_data)\n",
        "print(len(all_characters_in_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdTM4169H72N",
        "outputId": "26a68248-06ef-4fd2-94ff-43a2c56b91f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzL1kQWiICME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}